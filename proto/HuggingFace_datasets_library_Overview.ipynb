{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3.7.7 64-bit ('datasets': conda)",
      "language": "python",
      "name": "python37764bitdatasetscondae5d8ff60608e4c5c953d6bb643d8ebc5"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "b1-Kj1xQvSU_",
        "au4v3mOQvSVC",
        "cEnCi9DFvSVQ",
        "Q5vny56-vSVV",
        "G459HzD-vSVY",
        "xckhVEWFvSVb"
      ]
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f028d1b27b994dbfafdc4b620cbcadc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f1c137fe60b643bd97870d5fec3fb054",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_85337f11190147f09d7f28c45beb6bbd",
              "IPY_MODEL_09ef34993e3e477c927954c32cef75b7"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "f1c137fe60b643bd97870d5fec3fb054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "85337f11190147f09d7f28c45beb6bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_deae9e7ceed04b49800919964bb0d3eb",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2737,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2737,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_056450405d3c4239b7f7ac7b1a9244ba"
          },
          "model_module_version": "1.5.0"
        },
        "09ef34993e3e477c927954c32cef75b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_180080177ff04d2a834bd71cacdffd21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7.16k/? [00:07&lt;00:00, 903B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_383f9cefc6394bac81c6468c7245d9a7"
          },
          "model_module_version": "1.5.0"
        },
        "deae9e7ceed04b49800919964bb0d3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "056450405d3c4239b7f7ac7b1a9244ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "180080177ff04d2a834bd71cacdffd21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "383f9cefc6394bac81c6468c7245d9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "cb1a861322df4b6dbe161a083dc5d09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4b41568388c04de2afc9b4db49218114",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1ec66421dfca427286508348e3bf5a35",
              "IPY_MODEL_2902f213ba2e480d9c671b9d7b7ef904"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "4b41568388c04de2afc9b4db49218114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "1ec66421dfca427286508348e3bf5a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c17f8347b5fe499e8d4bbdecf37bf8db",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed24a2f75aa8467d98b4e3a40bed5915"
          },
          "model_module_version": "1.5.0"
        },
        "2902f213ba2e480d9c671b9d7b7ef904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e3a8e8d6f4946b091b7ead1eba28984",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 37.4k/? [00:00&lt;00:00, 336kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3df495af112d499e96371884182ae3ba"
          },
          "model_module_version": "1.5.0"
        },
        "c17f8347b5fe499e8d4bbdecf37bf8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "ed24a2f75aa8467d98b4e3a40bed5915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "8e3a8e8d6f4946b091b7ead1eba28984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "3df495af112d499e96371884182ae3ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "0a07c950dbe841e8aae7b6c46925dee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_238debfea9b447ec9787475c1a42d838",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f07183188a744bc49f092bb45532fa1d",
              "IPY_MODEL_dccee7c078b3402a9f67ff5239387871"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "238debfea9b447ec9787475c1a42d838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "f07183188a744bc49f092bb45532fa1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95149ea679384e57964aa70117e9c532",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 81853486,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 81853486,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_195cc73864e245d9a09802121e1451ed"
          },
          "model_module_version": "1.5.0"
        },
        "dccee7c078b3402a9f67ff5239387871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6663ea82bb004315a0b8b42c1be86302",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 81.9M/81.9M [00:06&lt;00:00, 12.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b7fd38de228435687046c6aff26a6d0"
          },
          "model_module_version": "1.5.0"
        },
        "95149ea679384e57964aa70117e9c532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "195cc73864e245d9a09802121e1451ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "6663ea82bb004315a0b8b42c1be86302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "5b7fd38de228435687046c6aff26a6d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "375744a8d32344ac960e7a192992a48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8aa8bdab792f48c39446fe65a980e18a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fbb195fc50cd426eb6908a4b7b362f79",
              "IPY_MODEL_42b547bf227e4fcb885bbb6bdd8fff06"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "8aa8bdab792f48c39446fe65a980e18a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "fbb195fc50cd426eb6908a4b7b362f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db1d1d7db24d4309ac08d140d221316e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2019337,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2019337,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e99b6b6d591c470b9a96380d4c36380a"
          },
          "model_module_version": "1.5.0"
        },
        "42b547bf227e4fcb885bbb6bdd8fff06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29868a2629d84eae9bdb57b48b8d80b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.02M/2.02M [00:01&lt;00:00, 1.08MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee5b0596882a4745ad045e3f90c8a569"
          },
          "model_module_version": "1.5.0"
        },
        "db1d1d7db24d4309ac08d140d221316e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "e99b6b6d591c470b9a96380d4c36380a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "29868a2629d84eae9bdb57b48b8d80b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "ee5b0596882a4745ad045e3f90c8a569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "7cdf084ef6d54b20b650c4cfeabd350c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b74069ca5279473998b14acb9b74889f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b47d9b3bf9c543538c2e8e87494390d6",
              "IPY_MODEL_c6fba328eb034eeb8771fefec7d1a182"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "b74069ca5279473998b14acb9b74889f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "b47d9b3bf9c543538c2e8e87494390d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab3c265b775e429a835cf6b6272fb035",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2044470,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2044470,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de77586948b749bdac8effe1a5312a5c"
          },
          "model_module_version": "1.5.0"
        },
        "c6fba328eb034eeb8771fefec7d1a182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c27ee7636e045f1b8dd6b39321e0fcb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.04M/2.04M [00:00&lt;00:00, 2.45MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed56707acb6747fcae1b8ae75b9e1291"
          },
          "model_module_version": "1.5.0"
        },
        "ab3c265b775e429a835cf6b6272fb035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "de77586948b749bdac8effe1a5312a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5c27ee7636e045f1b8dd6b39321e0fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "ed56707acb6747fcae1b8ae75b9e1291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "13aa181f0fb5424780978442aad48d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_affe9292143b43678c20110effba1ac6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c39b61925d2d45f582e9837ee4c016bc",
              "IPY_MODEL_2469af9ec4cd4e3a80ff3007d138401d"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "affe9292143b43678c20110effba1ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "c39b61925d2d45f582e9837ee4c016bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49e352632302493e8ff65d91aa29e56c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_402adf0b813d445aba30b9cacf3f360f"
          },
          "model_module_version": "1.5.0"
        },
        "2469af9ec4cd4e3a80ff3007d138401d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_462b82e1200f4f2aacb4169065fe2f68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200000/0 [00:17&lt;00:00, 15965.54 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d7c52cc392340c2912187bedcb79998"
          },
          "model_module_version": "1.5.0"
        },
        "49e352632302493e8ff65d91aa29e56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "402adf0b813d445aba30b9cacf3f360f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "462b82e1200f4f2aacb4169065fe2f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "3d7c52cc392340c2912187bedcb79998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "37c55b0c0d3642e8acfb5ee373e53b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3ee772d046524f5fbf62e89bed3bd02f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_35827b8528564df8935a81c61690ab40",
              "IPY_MODEL_3a792e01b52c49f794c1482fb65b897f"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "3ee772d046524f5fbf62e89bed3bd02f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "35827b8528564df8935a81c61690ab40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc4885bd6ce3410689b2120540fca2d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44fcc8bb6c2343c39c1d97e8f9ed5bd4"
          },
          "model_module_version": "1.5.0"
        },
        "3a792e01b52c49f794c1482fb65b897f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93ad9f9e5fda4ef8927cea2c0ad8f062",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5000/0 [00:00&lt;00:00, 9252.06 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66a8901ef5bc4964a5838ed9d6cfab29"
          },
          "model_module_version": "1.5.0"
        },
        "cc4885bd6ce3410689b2120540fca2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "44fcc8bb6c2343c39c1d97e8f9ed5bd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "93ad9f9e5fda4ef8927cea2c0ad8f062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "66a8901ef5bc4964a5838ed9d6cfab29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "e75d35f9b023459ba23be2cde445fc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_499f491ed3a1409fba99b80705eccfe6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_19bc09d7080e4eb19c60b5e01da963e9",
              "IPY_MODEL_3ca3018727f04505a2c5def9c9a89a5e"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "499f491ed3a1409fba99b80705eccfe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "19bc09d7080e4eb19c60b5e01da963e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2cf441d4f2164e62b018695013e25134",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_482dff9c579e4ffda11d9c14f97c480b"
          },
          "model_module_version": "1.5.0"
        },
        "3ca3018727f04505a2c5def9c9a89a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e8bea724a6344dd9e79ba9133f4ca3c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5000/0 [00:00&lt;00:00, 8436.76 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f4e333bb5ef4e9092ebc125e39fce7f"
          },
          "model_module_version": "1.5.0"
        },
        "2cf441d4f2164e62b018695013e25134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "482dff9c579e4ffda11d9c14f97c480b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "7e8bea724a6344dd9e79ba9133f4ca3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "0f4e333bb5ef4e9092ebc125e39fce7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "08236188125a4c2e931feb58ebe648c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_58f37f73168648a08edc0ae615260c24",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1da82f72f3fc46358fe3e4268e42d137",
              "IPY_MODEL_b051786ab97145cbb88627588bbec7d2"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "58f37f73168648a08edc0ae615260c24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "1da82f72f3fc46358fe3e4268e42d137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_97948303212c4a1982a6dda9dfd4cc90",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1057,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1057,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f252b203b8d349edb87b0a81209746b2"
          },
          "model_module_version": "1.5.0"
        },
        "b051786ab97145cbb88627588bbec7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37b19294c7464eb4bd886d966e148219",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1057/1057 [04:15&lt;00:00,  4.14ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1aa28417f911424eb9ac87413e4572ee"
          },
          "model_module_version": "1.5.0"
        },
        "97948303212c4a1982a6dda9dfd4cc90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "f252b203b8d349edb87b0a81209746b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "37b19294c7464eb4bd886d966e148219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "1aa28417f911424eb9ac87413e4572ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "ae210ea515f94c6ab34c1113e823b92d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_86c8850654d54b47a2771cbb1804f5a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_435d36683bc04e06a971b76129a88ed1",
              "IPY_MODEL_78ae08f5803f4cb29f7f63c2843e9db0"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "86c8850654d54b47a2771cbb1804f5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "435d36683bc04e06a971b76129a88ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_703443b26d7d40aea83417de59b64a79",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf940cf9ea3043b5abeb4c851ad23b77"
          },
          "model_module_version": "1.5.0"
        },
        "78ae08f5803f4cb29f7f63c2843e9db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e319f183228b4f0dba1140d9cc1573ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [03:25&lt;00:00, 102.76s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3d89c58eda640a6a8289ba0c5d549e2"
          },
          "model_module_version": "1.5.0"
        },
        "703443b26d7d40aea83417de59b64a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "cf940cf9ea3043b5abeb4c851ad23b77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "e319f183228b4f0dba1140d9cc1573ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "a3d89c58eda640a6a8289ba0c5d549e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "71d89e94d82f4335b7ca7aaf4dba83ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f38913964ddb4e3eb6fc0cf087ab0f52",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f03c8400d014b3bbb5e8dd4f63c5441",
              "IPY_MODEL_23f45949b7f949859ecabab44b591553"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "f38913964ddb4e3eb6fc0cf087ab0f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "4f03c8400d014b3bbb5e8dd4f63c5441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ae2be9ec40f424a8b1f5a8139f6de04",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 88,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 88,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb778df78c63405db22ede23c63f001a"
          },
          "model_module_version": "1.5.0"
        },
        "23f45949b7f949859ecabab44b591553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d46f8f656ea34972a4dd9b7554d62315",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 88/88 [00:29&lt;00:00,  2.97ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a57ecf5ee6e043458af851dfd2e0b50d"
          },
          "model_module_version": "1.5.0"
        },
        "3ae2be9ec40f424a8b1f5a8139f6de04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "cb778df78c63405db22ede23c63f001a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "d46f8f656ea34972a4dd9b7554d62315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "a57ecf5ee6e043458af851dfd2e0b50d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "90004c044a5c4fbb884f881d8bc1d54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_30e2b72ce2304332a202d92d606671f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_810d81cd651d41f298ff4815fcf9f34a",
              "IPY_MODEL_86fa8d2a2b204d8586cc8ab5ad2a1b7a"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "30e2b72ce2304332a202d92d606671f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "810d81cd651d41f298ff4815fcf9f34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6db8399610464d6e93ce82ad8bb7bfc4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f684dcff9d4c4c10b6bb623c02465b14"
          },
          "model_module_version": "1.5.0"
        },
        "86fa8d2a2b204d8586cc8ab5ad2a1b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_043e8d6ca6574bd4abcfdd7145162ceb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11/11 [00:03&lt;00:00,  2.91ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec53215a263e413eab01f74b66b9bff6"
          },
          "model_module_version": "1.5.0"
        },
        "6db8399610464d6e93ce82ad8bb7bfc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "f684dcff9d4c4c10b6bb623c02465b14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "043e8d6ca6574bd4abcfdd7145162ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "ec53215a263e413eab01f74b66b9bff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNp6kK7OvSUg"
      },
      "source": [
        "# HuggingFace `🤗Datasets` library - Quick overview\n",
        "\n",
        "Models come and go (linear models, LSTM, Transformers, ...) but two core elements have consistently been the beating heart of Natural Language Processing: Datasets & Metrics\n",
        "\n",
        "`🤗Datasets` is a fast and efficient library to easily share and load dataset and evaluation metrics, already providing access to 150+ datasets and 12+ evaluation metrics.\n",
        "\n",
        "The library has several interesting features (beside easy access to datasets/metrics):\n",
        "\n",
        "- Build-in interoperability with PyTorch, Tensorflow 2, Pandas and Numpy\n",
        "- Lighweight and fast library with a transparent and pythonic API\n",
        "- Strive on large datasets: frees you from RAM memory limits, all datasets are memory-mapped on drive by default.\n",
        "- Smart caching with an intelligent `tf.data`-like cache: never wait for your data to process several times\n",
        "\n",
        "`🤗Datasets` originated from a fork of the awesome Tensorflow-Datasets and the HuggingFace team want to deeply thank the team behind this amazing library and user API. We have tried to keep a layer of compatibility with `tfds` and a conversion can provide conversion from one format to the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzk9aEtIvSUh"
      },
      "source": [
        "# Main datasets API\n",
        "\n",
        "This notebook is a quick dive in the main user API for loading datasets in `datasets`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Elc-peYUIfau",
        "outputId": "aaa41c9e-0be8-44b8-fa8d-7bcb01241ff7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my95uHbLyjwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d1b724-a060-4f06-c054-d6c18be97524"
      },
      "source": [
        "# install datasets\n",
        "!pip install datasets\n",
        "\n",
        "# Make sure that we have a recent version of pyarrow in the session before we continue - otherwise reboot Colab to activate it\n",
        "import pyarrow\n",
        "if int(pyarrow.__version__.split('.')[1]) < 16 and int(pyarrow.__version__.split('.')[0]) == 0:\n",
        "    import os\n",
        "    os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/1a/b9f9b3bfef624686ae81c070f0a6bb635047b17cdb3698c7ad01281e6f9a/datasets-1.6.2-py3-none-any.whl (221kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 37.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: fsspec, xxhash, huggingface-hub, datasets\n",
            "Successfully installed datasets-1.6.2 fsspec-2021.4.0 huggingface-hub-0.0.8 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF66fKCg0JYP",
        "outputId": "40f9479c-347f-4bfb-9651-186ebd17e7ce"
      },
      "source": [
        "!pip install banal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting banal\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/c4/7f6e6a539cc6b2da4da3b6a58d5e6f9342c870522ee46d41f8cbd2156953/banal-1.0.6-py2.py3-none-any.whl\n",
            "Installing collected packages: banal\n",
            "Successfully installed banal-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au7Dyy_fLEYA",
        "outputId": "533a0280-2eb4-4440-80d3-6321a78d41ec"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVjXLiYxvSUl"
      },
      "source": [
        "# Let's import the library. We typically only need at most four methods:\n",
        "from datasets import list_datasets, list_metrics, load_dataset, load_metric\n",
        "import pandas as pd\n",
        "import json\n",
        "from pprint import pprint\n",
        "import re\n",
        "import os\n",
        "#import languagecodes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNloBBx-vSUo"
      },
      "source": [
        "## Listing the currently available datasets and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3RJisGLvSUp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ace6bc6-d0e1-4196-aedf-cd2d34d38aa4"
      },
      "source": [
        "# Currently available datasets and metrics\n",
        "datasets = list_datasets()\n",
        "metrics = list_metrics()\n",
        "\n",
        "print(f\"🤩 Currently {len(datasets)} datasets are available on the hub:\")\n",
        "pprint(datasets, compact=True)\n",
        "print(f\"🤩 Currently {len(metrics)} metrics are available on the hub:\")\n",
        "pprint(metrics, compact=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "🤩 Currently 862 datasets are available on the hub:\n",
            "['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc',\n",
            " 'afrikaans_ner_corpus', 'ag_news', 'ai2_arc', 'air_dialogue',\n",
            " 'ajgt_twitter_ar', 'allegro_reviews', 'allocine', 'alt', 'amazon_polarity',\n",
            " 'amazon_reviews_multi', 'amazon_us_reviews', 'ambig_qa', 'amttl', 'anli',\n",
            " 'app_reviews', 'aqua_rat', 'aquamuse', 'ar_cov19', 'ar_res_reviews',\n",
            " 'ar_sarcasm', 'arabic_billion_words', 'arabic_pos_dialect',\n",
            " 'arabic_speech_corpus', 'arcd', 'arsentd_lev', 'art', 'arxiv_dataset',\n",
            " 'aslg_pc12', 'asnq', 'asset', 'assin', 'assin2', 'atomic', 'autshumato',\n",
            " 'babi_qa', 'banking77', 'bbc_hindi_nli', 'bc2gm_corpus', 'best2009', 'bianet',\n",
            " 'bible_para', 'big_patent', 'billsum', 'bing_coronavirus_query_set', 'biomrc',\n",
            " 'blended_skill_talk', 'blimp', 'blog_authorship_corpus', 'bn_hate_speech',\n",
            " 'bookcorpus', 'bookcorpusopen', 'boolq', 'bprec', 'break_data', 'brwac',\n",
            " 'bsd_ja_en', 'bswac', 'c3', 'c4', 'cail2018', 'caner', 'capes',\n",
            " 'catalonia_independence', 'cawac', 'cbt', 'cc100', 'cc_news',\n",
            " 'ccaligned_multilingual', 'cdsc', 'cdt', 'cfq', 'chr_en', 'cifar10',\n",
            " 'cifar100', 'circa', 'civil_comments', 'clickbait_news_bg', 'climate_fever',\n",
            " 'clinc_oos', 'clue', 'cmrc2018', 'cnn_dailymail', 'coached_conv_pref',\n",
            " 'coarse_discourse', 'codah', 'code_search_net', 'com_qa', 'common_gen',\n",
            " 'common_voice', 'commonsense_qa', 'compguesswhat', 'conceptnet5', 'conll2000',\n",
            " 'conll2002', 'conll2003', 'conllpp', 'conv_ai', 'conv_ai_2', 'conv_ai_3',\n",
            " 'coqa', 'cord19', 'cornell_movie_dialog', 'cos_e', 'cosmos_qa', 'counter',\n",
            " 'covid_qa_castorini', 'covid_qa_deepset', 'covid_qa_ucsd',\n",
            " 'covid_tweets_japanese', 'covost2', 'craigslist_bargains', 'crawl_domain',\n",
            " 'crd3', 'crime_and_punish', 'crows_pairs', 'cryptonite', 'cs_restaurants',\n",
            " 'cuad', 'curiosity_dialogs', 'daily_dialog', 'dane',\n",
            " 'danish_political_comments', 'dart', 'datacommons_factcheck', 'dbpedia_14',\n",
            " 'dbrd', 'deal_or_no_dialog', 'definite_pronoun_resolution', 'dengue_filipino',\n",
            " 'dialog_re', 'diplomacy_detection', 'disaster_response_messages', 'discofuse',\n",
            " 'discovery', 'doc2dial', 'docred', 'doqa', 'dream', 'drop', 'duorc',\n",
            " 'dutch_social', 'dyk', 'e2e_nlg', 'e2e_nlg_cleaned', 'ecb', 'ecthr_cases',\n",
            " 'ehealth_kd', 'eitb_parcc', 'eli5', 'emea', 'emo', 'emotion', 'emotone_ar',\n",
            " 'empathetic_dialogues', 'enriched_web_nlg', 'eraser_multi_rc', 'esnli',\n",
            " 'eth_py150_open', 'ethos', 'eu_regulatory_ir', 'eurlex', 'euronews',\n",
            " 'europa_eac_tm', 'europa_ecdc_tm', 'europarl_bilingual', 'event2Mind',\n",
            " 'evidence_infer_treatment', 'exams', 'factckbr', 'fake_news_english',\n",
            " 'fake_news_filipino', 'farsi_news', 'fashion_mnist', 'fever', 'few_rel',\n",
            " 'financial_phrasebank', 'finer', 'flores', 'flue', 'fquad', 'freebase_qa',\n",
            " 'gap', 'gem', 'generated_reviews_enth', 'generics_kb',\n",
            " 'german_legal_entity_recognition', 'germaner', 'germeval_14', 'giga_fren',\n",
            " 'gigaword', 'glucose', 'glue', 'gnad10', 'go_emotions',\n",
            " 'google_wellformed_query', 'grail_qa', 'great_code', 'guardian_authorship',\n",
            " 'gutenberg_time', 'hans', 'hansards', 'hard', 'harem', 'has_part',\n",
            " 'hate_offensive', 'hate_speech18', 'hate_speech_filipino',\n",
            " 'hate_speech_offensive', 'hate_speech_pl', 'hate_speech_portuguese',\n",
            " 'hatexplain', 'hausa_voa_ner', 'hausa_voa_topics', 'hda_nli_hindi', 'head_qa',\n",
            " 'health_fact', 'hebrew_projectbenyehuda', 'hebrew_sentiment',\n",
            " 'hebrew_this_world', 'hellaswag', 'hind_encorp', 'hindi_discourse',\n",
            " 'hippocorpus', 'hkcancor', 'hope_edi', 'hotpot_qa', 'hover', 'hrenwac_para',\n",
            " 'hrwac', 'humicroedit', 'hybrid_qa', 'hyperpartisan_news_detection',\n",
            " 'iapp_wiki_qa_squad', 'id_clickbait', 'id_liputan6', 'id_nergrit_corpus',\n",
            " 'id_newspapers_2018', 'id_panl_bppt', 'id_puisi',\n",
            " 'igbo_english_machine_translation', 'igbo_monolingual', 'igbo_ner', 'ilist',\n",
            " 'imdb', 'imdb_urdu_reviews', 'imppres', 'indic_glue', 'indonlu',\n",
            " 'inquisitive_qg', 'interpress_news_category_tr',\n",
            " 'interpress_news_category_tr_lite', 'irc_disentangle', 'isixhosa_ner_corpus',\n",
            " 'isizulu_ner_corpus', 'iwslt2017', 'jeopardy', 'jfleg', 'jigsaw_toxicity_pred',\n",
            " 'jnlpba', 'journalists_questions', 'kannada_news', 'kd_conv', 'kde4', 'kelm',\n",
            " 'kilt_tasks', 'kilt_wikipedia', 'kinnews_kirnews', 'kor_3i4k', 'kor_hate',\n",
            " 'kor_ner', 'kor_nli', 'kor_nlu', 'kor_qpair', 'kor_sae', 'kor_sarcasm', 'labr',\n",
            " 'lama', 'lambada', 'large_spanish_corpus', 'laroseda', 'lc_quad', 'lener_br',\n",
            " 'liar', 'librispeech_asr', 'librispeech_lm', 'limit', 'lince', 'linnaeus',\n",
            " 'liveqa', 'lj_speech', 'lm1b', 'lst20', 'm_lama', 'mac_morpho', 'makhzan',\n",
            " 'math_dataset', 'math_qa', 'matinf', 'mc_taco', 'md_gender_bias', 'mdd',\n",
            " 'med_hop', 'medal', 'medical_dialog', 'medical_questions_pairs', 'menyo20k_mt',\n",
            " 'meta_woz', 'metooma', 'metrec', 'miam', 'mkb', 'mkqa', 'mlqa', 'mlsum',\n",
            " 'mnist', 'mocha', 'moroco', 'movie_rationales', 'mrqa', 'ms_marco', 'ms_terms',\n",
            " 'msr_genomics_kbcomp', 'msr_sqa', 'msr_text_compression',\n",
            " 'msr_zhen_translation_parity', 'msra_ner', 'mt_eng_vietnamese', 'muchocine',\n",
            " 'multi_booked', 'multi_news', 'multi_nli', 'multi_nli_mismatch',\n",
            " 'multi_para_crawl', 'multi_re_qa', 'multi_woz_v22', 'multi_x_science_sum',\n",
            " 'mutual_friends', 'mwsc', 'myanmar_news', 'narrativeqa', 'narrativeqa_manual',\n",
            " 'natural_questions', 'ncbi_disease', 'nchlt', 'ncslgr', 'nell',\n",
            " 'neural_code_search', 'news_commentary', 'newsgroup', 'newsph', 'newsph_nli',\n",
            " 'newspop', 'newsqa', 'newsroom', 'nkjp-ner', 'nli_tr', 'nlu_evaluation_data',\n",
            " 'norec', 'norne', 'norwegian_ner', 'nq_open', 'nsmc', 'numer_sense',\n",
            " 'numeric_fused_head', 'oclar', 'offcombr', 'offenseval2020_tr',\n",
            " 'offenseval_dravidian', 'ofis_publik', 'ohsumed', 'ollie', 'omp',\n",
            " 'onestop_english', 'open_subtitles', 'openbookqa', 'openslr', 'openwebtext',\n",
            " 'opinosis', 'opus100', 'opus_books', 'opus_dgt', 'opus_dogc', 'opus_elhuyar',\n",
            " 'opus_euconst', 'opus_finlex', 'opus_fiskmo', 'opus_gnome', 'opus_infopankki',\n",
            " 'opus_memat', 'opus_montenegrinsubs', 'opus_openoffice', 'opus_paracrawl',\n",
            " 'opus_rf', 'opus_tedtalks', 'opus_ubuntu', 'opus_wikipedia', 'opus_xhosanavy',\n",
            " 'orange_sum', 'oscar', 'para_crawl', 'para_pat',\n",
            " 'parsinlu_reading_comprehension', 'paws', 'paws-x', 'pec', 'peer_read',\n",
            " 'peoples_daily_ner', 'per_sent', 'persian_ner', 'pg19', 'php', 'piaf', 'pib',\n",
            " 'piqa', 'pn_summary', 'poem_sentiment', 'polemo2', 'poleval2019_cyberbullying',\n",
            " 'poleval2019_mt', 'polsum', 'polyglot_ner', 'prachathai67k', 'pragmeval',\n",
            " 'proto_qa', 'psc', 'ptb_text_only', 'pubmed', 'pubmed_qa', 'py_ast', 'qa4mre',\n",
            " 'qa_srl', 'qa_zre', 'qangaroo', 'qanta', 'qasc', 'qed', 'qed_amara', 'quac',\n",
            " 'quail', 'quarel', 'quartz', 'quora', 'quoref', 'race', 're_dial',\n",
            " 'reasoning_bg', 'recipe_nlg', 'reclor', 'reddit', 'reddit_tifu', 'refresd',\n",
            " 'reuters21578', 'ro_sent', 'ro_sts', 'ro_sts_parallel', 'roman_urdu', 'ronec',\n",
            " 'ropes', 'rotten_tomatoes', 's2orc', 'samsum', 'sanskrit_classic',\n",
            " 'saudinewsnet', 'scan', 'scb_mt_enth_2020', 'schema_guided_dstc8', 'scicite',\n",
            " 'scielo', 'scientific_papers', 'scifact', 'sciq', 'scitail', 'scitldr',\n",
            " 'search_qa', 'selqa', 'sem_eval_2010_task_8', 'sem_eval_2014_task_1',\n",
            " 'sem_eval_2020_task_11', 'sent_comp', 'senti_lex', 'senti_ws', 'sentiment140',\n",
            " 'sepedi_ner', 'sesotho_ner_corpus', 'setimes', 'setswana_ner_corpus', 'sharc',\n",
            " 'sharc_modified', 'sick', 'silicone', 'simple_questions_v2',\n",
            " 'siswati_ner_corpus', 'smartdata', 'sms_spam', 'snips_built_in_intents',\n",
            " 'snli', 'snow_simplified_japanese_corpus', 'so_stacksample',\n",
            " 'social_bias_frames', 'social_i_qa', 'sofc_materials_articles', 'sogou_news',\n",
            " 'spanish_billion_words', 'spc', 'species_800', 'spider', 'squad',\n",
            " 'squad_adversarial', 'squad_es', 'squad_it', 'squad_kor_v1', 'squad_kor_v2',\n",
            " 'squad_v1_pt', 'squad_v2', 'squadshifts', 'srwac', 'sst', 'stereoset',\n",
            " 'stsb_mt_sv', 'stsb_multi_mt', 'style_change_detection', 'super_glue', 'swag',\n",
            " 'swahili', 'swahili_news', 'swda', 'swedish_ner_corpus', 'swedish_reviews',\n",
            " 'tab_fact', 'tamilmixsentiment', 'tanzil', 'tapaco', 'tashkeela',\n",
            " 'taskmaster1', 'taskmaster2', 'taskmaster3', 'tatoeba', 'ted_hrlr',\n",
            " 'ted_iwlst2013', 'ted_multi', 'ted_talks_iwslt', 'telugu_books', 'telugu_news',\n",
            " 'tep_en_fa_para', 'thai_toxicity_tweet', 'thainer', 'thaiqa_squad', 'thaisum',\n",
            " 'tilde_model', 'times_of_india_news_headlines', 'timit_asr',\n",
            " 'tiny_shakespeare', 'tlc', 'tmu_gfm_dataset', 'totto', 'trec', 'trivia_qa',\n",
            " 'tsac', 'ttc4900', 'tunizi', 'tuple_ie', 'turk', 'turkish_movie_sentiment',\n",
            " 'turkish_ner', 'turkish_product_reviews', 'turkish_shrinked_ner',\n",
            " 'turku_ner_corpus', 'tweet_eval', 'tweet_qa', 'tweets_ar_en_parallel',\n",
            " 'tweets_hate_speech_detection', 'twi_text_c3', 'twi_wordsim353', 'tydiqa',\n",
            " 'ubuntu_dialogs_corpus', 'udhr', 'um005', 'un_ga', 'un_multi', 'un_pc',\n",
            " 'universal_dependencies', 'universal_morphologies', 'urdu_fake_news',\n",
            " 'urdu_sentiment_corpus', 'web_nlg', 'web_of_science', 'web_questions',\n",
            " 'weibo_ner', 'wi_locness', 'wiki40b', 'wiki_asp', 'wiki_atomic_edits',\n",
            " 'wiki_auto', 'wiki_bio', 'wiki_dpr', 'wiki_hop', 'wiki_lingua', 'wiki_movies',\n",
            " 'wiki_qa', 'wiki_qa_ar', 'wiki_snippets', 'wiki_source', 'wiki_split',\n",
            " 'wiki_summary', 'wikiann', 'wikicorpus', 'wikihow', 'wikipedia', 'wikisql',\n",
            " 'wikitext', 'wikitext_tl39', 'wili_2018', 'wino_bias', 'winograd_wsc',\n",
            " 'winogrande', 'wiqa', 'wisesight1000', 'wisesight_sentiment', 'wmt14', 'wmt15',\n",
            " 'wmt16', 'wmt17', 'wmt18', 'wmt19', 'wmt20_mlqe_task1', 'wmt20_mlqe_task2',\n",
            " 'wmt20_mlqe_task3', 'wmt_t2t', 'wnut_17', 'wongnai_reviews', 'woz_dialogue',\n",
            " 'wrbsc', 'x_stance', 'xcopa', 'xed_en_fi', 'xglue', 'xnli', 'xor_tydi_qa',\n",
            " 'xquad', 'xquad_r', 'xsum', 'xsum_factuality', 'xtreme', 'yahoo_answers_qa',\n",
            " 'yahoo_answers_topics', 'yelp_polarity', 'yelp_review_full',\n",
            " 'yoruba_bbc_topics', 'yoruba_gv_ner', 'yoruba_text_c3', 'yoruba_wordsim353',\n",
            " 'youtube_caption_corrections', 'zest', 'AConsApart/anime_subtitles_DialoGPT',\n",
            " 'Adnan/Urdu_News_Headlines', 'Avishekavi/Avi', 'Binbin/my_dataset',\n",
            " 'EMBO/biolang', 'EMBO/sd-nlp', 'Eymen3455/xsum_tr', 'FRTNX/cosuju',\n",
            " 'Firoj/CrisisBench', 'Fraser/mnist-text-default',\n",
            " 'Fraser/mnist-text-no-spaces', 'Fraser/mnist-text-small',\n",
            " 'Fraser/news-category-dataset', 'Fraser/python-lines', 'Fraser/short-jokes',\n",
            " 'Halilyesilceng/autonlp-data-nameEntityRecognition',\n",
            " 'Harveenchadha/Gujarati-Monolingual-Data', 'Jean-Baptiste/wikiner_fr',\n",
            " 'KidDiabeetus/Unhinged', 'MarianaSahagun/test', 'Melinoe/TheLabTexts',\n",
            " 'NTUYG/RAGTest', 'NbAiLab/norec_agg', 'NbAiLab/norne',\n",
            " 'NbAiLab/norwegian_parliament', 'Ofrit/tmp', 'QA/abk-eng',\n",
            " 'SajjadAyoubi/persian_qa', 'TRoboto/masc', 'Terry0107/RiSAWOZ',\n",
            " 'TimTreasure4/Test', 'Trainmaster9977/957', 'Trainmaster9977/zbakuman',\n",
            " 'Tyler/wikimatrix_collapsed', 'Valahaar/wsdmt', 'Vishva/UniFAQ_DataSET',\n",
            " 'Wikidepia/IndoParaCrawl', 'Wikidepia/IndoSQuAD', 'XiangXiang/clt',\n",
            " 'Yves/fhnw_swiss_parliament', 'abhishek/autonlp-data-imdb_eval',\n",
            " 'abwicke/C-B-R', 'abwicke/koplo', 'adamlin/re_dial', 'ajmbell/test-dataset',\n",
            " 'alireza655/alireza655', 'allenai/c4', 'ancs21/viwiki-18042021',\n",
            " 'anukaver/EstQA', 'aschvin/fhnw_test', 'ashish-shrivastava/dont-know-dataset',\n",
            " 'astarostap/antisemitic-tweets', 'astarostap/antisemitic_tweets',\n",
            " 'athivvat/thai-rap-lyrics', 'ausgequetschtem/jtrddfhfgh',\n",
            " 'bavard/personachat_truecased', 'bemanningssitua/dplremjfjfj', 'caca/zscczs',\n",
            " 'canwenxu/dogwhistle', 'ccccccc/hdjw_94ejrjr', 'cdminix/mgb1',\n",
            " 'cemigo/taylor_vs_shakes', 'cemigo/test-data', 'clarin-pl/cst-wikinews',\n",
            " 'clarin-pl/nkjp-pos', 'clarin-pl/polemo2-official', 'classla/copa_hr',\n",
            " 'classla/hr500k', 'classla/reldi_hr', 'classla/reldi_sr', 'classla/setimes_sr',\n",
            " 'cnrcastroli/aaaa', 'congpt/dstc23_asr', 'dasago78/dasago78dataset',\n",
            " 'david-wb/zeshel', 'dfgvhxfgv/fghghj', 'dispenst/jhghdghfd',\n",
            " 'dispix/test-dataset', 'dynabench/dynasent', 'dynabench/qa', 'eason929/test',\n",
            " 'edfews/szdfcszdf', 'ervis/aaa', 'ervis/qqq', 'formermagic/github_python_1m',\n",
            " 'formu/CVT', 'fulai/DuReader', 'fuliucansheng/data_for_test',\n",
            " 'german-nlp-group/german_common_crawl', 'godzillavskongonlinetv/ergfdg',\n",
            " 'godzillavskongonlinetv/godzillavskongfullmovie',\n",
            " 'gustavecortal/fr_covid_news', 'hartzeer/kdfjdshfje', 'hfface/poopi',\n",
            " 'iamshsdf/sssssssssss', 'jaimin/wav2vec2-large-xlsr-gujarati-demo',\n",
            " 'jdepoix/junit_test_completion', 'jimregan/clarinpl_sejmsenat',\n",
            " 'jimregan/clarinpl_studio', 'joelito/ler', 'joelito/sem_eval_2010_task_8',\n",
            " 'julien-c/dummy-dataset-from-colab', 'k-halid/ar', 'katoensp/VR-OP',\n",
            " 'lavis-nlp/german_legal_sentences', 'lhoestq/custom_squad', 'lhoestq/squad',\n",
            " 'lhoestq/test', 'lhoestq/wikipedia_bn', 'lkiouiou/o9ui7877687',\n",
            " 'lohanna/testedjkcxkf', 'lucien/sciencemission', 'lucien/voacantonesed',\n",
            " 'lucien/wsaderfffjjjhhh', 'lucio/common_voice_eval',\n",
            " 'majod/CleanNaturalQuestionsDataset', 'makanan/umich', 'medzaf/test',\n",
            " 'metalearning/kaggale-nlp-tutorial', 'mmm-da/rutracker_anime_torrent_titles',\n",
            " 'mohsenfayyaz/toxicity-classification-datasets', 'mulcyber/europarl-mono',\n",
            " 'mustafa12/db_ee', 'mustafa12/edaaaas', 'mustafa12/thors',\n",
            " 'nucklehead/ht-voice-dataset', 'oelkrise/CRT',\n",
            " 'parivartanayurveda/Malesexproblemsayurvedictreatment',\n",
            " 'patrickvonplaten/librispeech_asr_dummy',\n",
            " 'patrickvonplaten/scientific_papers_dummy', 'pdesoyres/test',\n",
            " 'peixian/equity_evaluation_corpus', 'peixian/rtGender',\n",
            " 'persiannlp/parsinlu_entailment', 'persiannlp/parsinlu_query_paraphrasing',\n",
            " 'persiannlp/parsinlu_reading_comprehension', 'persiannlp/parsinlu_sentiment',\n",
            " 'persiannlp/parsinlu_translation_en_fa',\n",
            " 'persiannlp/parsinlu_translation_fa_en', 'piEsposito/br-quad-2.0',\n",
            " 'piEsposito/br_quad_20', 'piEsposito/squad_20_ptbr',\n",
            " 'princeton-nlp/datasets-for-simcse',\n",
            " 'projectaligned/reddit_writingprompts_full', 'rony/soccer-dialogues',\n",
            " 'roskoN/dstc8-reddit-corpus', 'salesken/Paraphrase_category_detection',\n",
            " 'scrapfast/news_french_2020', 'sdfufygvjh/fgghuviugviu', 'seamew/Weibo',\n",
            " 'seamew/amazon_reviews_zh', 'seamew/weibo_avg', 'sharejing/BiPaR',\n",
            " 'sismetanin/rureviews', 'spacemanidol/msmarco_passage_ranking',\n",
            " 'ssasaa/gghghgh', 'sshleifer/pseudo_bart_xsum',\n",
            " 'stas/wmt14-en-de-pre-processed', 'stas/wmt16-en-ro-pre-processed',\n",
            " 'stiel/skjdhjkasdhasjkd', 'susumu2357/squad_v2_sv', 'tals/test',\n",
            " 'toriving/agnews', 'toriving/atis-intent', 'toriving/cola', 'toriving/cr',\n",
            " 'toriving/dbpedia-content', 'toriving/dbpedia', 'toriving/imdb',\n",
            " 'toriving/mpqa', 'toriving/mr', 'toriving/rotten-tomato',\n",
            " 'toriving/snips-intent', 'toriving/sst2', 'toriving/sst5', 'toriving/subj',\n",
            " 'toriving/trec6', 'toriving/yahoo-answers', 'toriving/yelp',\n",
            " 'turingbench/TuringBench', 'uasoyasser/rgfes',\n",
            " 'vasudevgupta/bigbird-tokenized-natural-questions', 'vasudevgupta/data',\n",
            " 'vasudevgupta/natural-questions-validation',\n",
            " 'vasudevgupta/temperature-distribution-2d-plate',\n",
            " 'vasudevgupta/temperature-distribution-3d-cylinder', 'versae/adobo',\n",
            " 'vershasaxena91/datasets', 'vershasaxena91/squad_multitask',\n",
            " 'w11wo/imdb-javanese', 'webek18735/ddvoacantonesed', 'webek18735/dhikhscook',\n",
            " 'wmt/europarl', 'wmt/news-commentary', 'wmt/uncorpus', 'wmt/wikititles',\n",
            " 'wmt/wmt10', 'wmt/wmt13', 'wmt/wmt14', 'wmt/wmt15', 'wmt/wmt16', 'wmt/wmt17',\n",
            " 'wmt/wmt18', 'wmt/wmt19', 'yluisfern/PBU']\n",
            "🤩 Currently 24 metrics are available on the hub:\n",
            "['accuracy', 'bertscore', 'bleu', 'bleurt', 'cer', 'comet', 'coval', 'cuad',\n",
            " 'f1', 'gleu', 'glue', 'indic_glue', 'meteor', 'precision', 'recall', 'rouge',\n",
            " 'sacrebleu', 'sari', 'seqeval', 'squad', 'squad_v2', 'super_glue', 'wer',\n",
            " 'xnli']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T5AG3BxvSUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21eee95d-54d4-4d75-8a73-639e37b46cbd"
      },
      "source": [
        "# You can access various attributes of the datasets before downloading them\n",
        "amazon_dataset = list_datasets(with_details=True)[datasets.index('amazon_reviews_multi')]\n",
        "\n",
        "pprint(amazon_dataset.__dict__)  # It's a simple python dataclass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'author': None,\n",
            " 'citation': '@inproceedings{marc_reviews,\\n'\n",
            "             '    title={The Multilingual Amazon Reviews Corpus},\\n'\n",
            "             '    author={Keung, Phillip and Lu, Yichao and Szarvas, György '\n",
            "             'and Smith, Noah A.},\\n'\n",
            "             '    booktitle={Proceedings of the 2020 Conference on Empirical '\n",
            "             'Methods in Natural Language Processing},\\n'\n",
            "             '    year={2020}\\n'\n",
            "             '}',\n",
            " 'description': 'We provide an Amazon product reviews dataset for multilingual '\n",
            "                'text classification. The dataset contains reviews in English, '\n",
            "                'Japanese, German, French, Chinese and Spanish, collected '\n",
            "                'between November 1, 2015 and November 1, 2019. Each record in '\n",
            "                'the dataset contains the review text, the review title, the '\n",
            "                'star rating, an anonymized reviewer ID, an anonymized product '\n",
            "                'ID and the coarse-grained product category (e.g. ‘books’, '\n",
            "                '‘appliances’, etc.) The corpus is balanced across stars, so '\n",
            "                'each star rating constitutes 20% of the reviews in each '\n",
            "                'language.\\n'\n",
            "                '\\n'\n",
            "                'For each language, there are 200,000, 5,000 and 5,000 reviews '\n",
            "                'in the training, development and test sets respectively. The '\n",
            "                'maximum number of reviews per reviewer is 20 and the maximum '\n",
            "                'number of reviews per product is 20. All reviews are '\n",
            "                'truncated after 2,000 characters, and all reviews are at '\n",
            "                'least 20 characters long.\\n'\n",
            "                '\\n'\n",
            "                'Note that the language of a review does not necessarily match '\n",
            "                'the language of its marketplace (e.g. reviews from amazon.de '\n",
            "                'are primarily written in German, but could also be written in '\n",
            "                'English, etc.). For this reason, we applied a language '\n",
            "                'detection algorithm based on the work in Bojanowski et al. '\n",
            "                '(2017) to determine the language of the review text and we '\n",
            "                'removed reviews that were not written in the expected '\n",
            "                'language.',\n",
            " 'etag': None,\n",
            " 'id': 'amazon_reviews_multi',\n",
            " 'key': '',\n",
            " 'lastModified': None,\n",
            " 'siblings': None,\n",
            " 'size': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GIDIYU_Gd5G"
      },
      "source": [
        "# **Start HERE!**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uqSkkSovSUt"
      },
      "source": [
        "## An example with AMazon_review\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOXl6afcvSUu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "f028d1b27b994dbfafdc4b620cbcadc4",
            "f1c137fe60b643bd97870d5fec3fb054",
            "85337f11190147f09d7f28c45beb6bbd",
            "09ef34993e3e477c927954c32cef75b7",
            "deae9e7ceed04b49800919964bb0d3eb",
            "056450405d3c4239b7f7ac7b1a9244ba",
            "180080177ff04d2a834bd71cacdffd21",
            "383f9cefc6394bac81c6468c7245d9a7",
            "cb1a861322df4b6dbe161a083dc5d09c",
            "4b41568388c04de2afc9b4db49218114",
            "1ec66421dfca427286508348e3bf5a35",
            "2902f213ba2e480d9c671b9d7b7ef904",
            "c17f8347b5fe499e8d4bbdecf37bf8db",
            "ed24a2f75aa8467d98b4e3a40bed5915",
            "8e3a8e8d6f4946b091b7ead1eba28984",
            "3df495af112d499e96371884182ae3ba",
            "0a07c950dbe841e8aae7b6c46925dee3",
            "238debfea9b447ec9787475c1a42d838",
            "f07183188a744bc49f092bb45532fa1d",
            "dccee7c078b3402a9f67ff5239387871",
            "95149ea679384e57964aa70117e9c532",
            "195cc73864e245d9a09802121e1451ed",
            "6663ea82bb004315a0b8b42c1be86302",
            "5b7fd38de228435687046c6aff26a6d0",
            "375744a8d32344ac960e7a192992a48a",
            "8aa8bdab792f48c39446fe65a980e18a",
            "fbb195fc50cd426eb6908a4b7b362f79",
            "42b547bf227e4fcb885bbb6bdd8fff06",
            "db1d1d7db24d4309ac08d140d221316e",
            "e99b6b6d591c470b9a96380d4c36380a",
            "29868a2629d84eae9bdb57b48b8d80b3",
            "ee5b0596882a4745ad045e3f90c8a569",
            "7cdf084ef6d54b20b650c4cfeabd350c",
            "b74069ca5279473998b14acb9b74889f",
            "b47d9b3bf9c543538c2e8e87494390d6",
            "c6fba328eb034eeb8771fefec7d1a182",
            "ab3c265b775e429a835cf6b6272fb035",
            "de77586948b749bdac8effe1a5312a5c",
            "5c27ee7636e045f1b8dd6b39321e0fcb",
            "ed56707acb6747fcae1b8ae75b9e1291",
            "13aa181f0fb5424780978442aad48d1f",
            "affe9292143b43678c20110effba1ac6",
            "c39b61925d2d45f582e9837ee4c016bc",
            "2469af9ec4cd4e3a80ff3007d138401d",
            "49e352632302493e8ff65d91aa29e56c",
            "402adf0b813d445aba30b9cacf3f360f",
            "462b82e1200f4f2aacb4169065fe2f68",
            "3d7c52cc392340c2912187bedcb79998",
            "37c55b0c0d3642e8acfb5ee373e53b21",
            "3ee772d046524f5fbf62e89bed3bd02f",
            "35827b8528564df8935a81c61690ab40",
            "3a792e01b52c49f794c1482fb65b897f",
            "cc4885bd6ce3410689b2120540fca2d0",
            "44fcc8bb6c2343c39c1d97e8f9ed5bd4",
            "93ad9f9e5fda4ef8927cea2c0ad8f062",
            "66a8901ef5bc4964a5838ed9d6cfab29",
            "e75d35f9b023459ba23be2cde445fc77",
            "499f491ed3a1409fba99b80705eccfe6",
            "19bc09d7080e4eb19c60b5e01da963e9",
            "3ca3018727f04505a2c5def9c9a89a5e",
            "2cf441d4f2164e62b018695013e25134",
            "482dff9c579e4ffda11d9c14f97c480b",
            "7e8bea724a6344dd9e79ba9133f4ca3c",
            "0f4e333bb5ef4e9092ebc125e39fce7f"
          ]
        },
        "outputId": "0ac78ac0-cdc5-42d8-c70d-46e8da3b0e72"
      },
      "source": [
        "# Downloading and loading a dataset\n",
        "# train_test_ds = load_dataset('yoruba_bbc_topics',  split='train+test')#, split='validation[:10%]')\n",
        "# train_test_ds = load_dataset(\"cc100\", lang=\"yo\", split='train+test')\n",
        "# train_test_ds = load_dataset(\"wikiann\",\"rw\", split='train+test')\n",
        "# train_test_ds = load_dataset(\"wili_2018\", split='train')\n",
        "#dataset = load_dataset(\"flue\",'CLS', split='train+test+validation')\n",
        "dataset_train = load_dataset('amazon_reviews_multi', 'fr', split='train')\n",
        "dataset_test = load_dataset('amazon_reviews_multi', 'fr', split='test')\n",
        "dataset_val = load_dataset('amazon_reviews_multi', 'fr', split='validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f028d1b27b994dbfafdc4b620cbcadc4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2737.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb1a861322df4b6dbe161a083dc5d09c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=3624.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and preparing dataset amazon_reviews_multi/fr (download: 81.94 MiB, generated: 54.64 MiB, post-processed: Unknown size, total: 136.58 MiB) to /root/.cache/huggingface/datasets/amazon_reviews_multi/fr/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a07c950dbe841e8aae7b6c46925dee3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=81853486.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "375744a8d32344ac960e7a192992a48a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2019337.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cdf084ef6d54b20b650c4cfeabd350c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2044470.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13aa181f0fb5424780978442aad48d1f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37c55b0c0d3642e8acfb5ee373e53b21",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e75d35f9b023459ba23be2cde445fc77",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset amazon_reviews_multi downloaded and prepared to /root/.cache/huggingface/datasets/amazon_reviews_multi/fr/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/fr/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n",
            "Reusing dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/fr/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ0G-eK3vSUw"
      },
      "source": [
        "This call to `datasets.load_dataset()` does the following steps under the hood:\n",
        "\n",
        "1. Download and import in the library the **SQuAD python processing script** from HuggingFace AWS bucket if it's not already stored in the library. You can find the SQuAD processing script [here](https://github.com/huggingface/datasets/tree/master/datasets/squad/squad.py) for instance.\n",
        "\n",
        "   Processing scripts are small python scripts which define the info (citation, description) and format of the dataset and contain the URL to the original SQuAD JSON files and the code to load examples from the original SQuAD JSON files.\n",
        "\n",
        "\n",
        "2. Run the SQuAD python processing script which will:\n",
        "    - **Download the SQuAD dataset** from the original URL (see the script) if it's not already downloaded and cached.\n",
        "    - **Process and cache** all SQuAD in a structured Arrow table for each standard splits stored on the drive.\n",
        "\n",
        "      Arrow table are arbitrarily long tables, typed with types that can be mapped to numpy/pandas/python standard types and can store nested objects. They can be directly access from drive, loaded in RAM or even streamed over the web.\n",
        "    \n",
        "\n",
        "3. Return a **dataset built from the splits** asked by the user (default: all); in the above example we create a dataset with the first 10% of the validation split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQSrehebvPz8",
        "outputId": "ee788fdb-de3d-4611-e63c-10ffc066b26e"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fercoFwLvSUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6dcad3-8760-488d-a4a9-618634de23bf"
      },
      "source": [
        "# Informations on the dataset (description, citation, size, splits, format...)\n",
        "# are provided in `dataset.info` (a simple python dataclass) and also as direct attributes in the dataset object\n",
        "pprint(dataset_train.info.__dict__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'builder_name': 'amazon_reviews_multi',\n",
            " 'citation': '@inproceedings{marc_reviews,\\n'\n",
            "             '    title={The Multilingual Amazon Reviews Corpus},\\n'\n",
            "             '    author={Keung, Phillip and Lu, Yichao and Szarvas, György '\n",
            "             'and Smith, Noah A.},\\n'\n",
            "             '    booktitle={Proceedings of the 2020 Conference on Empirical '\n",
            "             'Methods in Natural Language Processing},\\n'\n",
            "             '    year={2020}\\n'\n",
            "             '}\\n',\n",
            " 'config_name': 'fr',\n",
            " 'dataset_size': 57298838,\n",
            " 'description': 'We provide an Amazon product reviews dataset for multilingual '\n",
            "                'text classification. The dataset contains reviews in English, '\n",
            "                'Japanese, German, French, Chinese and Spanish, collected '\n",
            "                'between November 1, 2015 and November 1, 2019. Each record in '\n",
            "                'the dataset contains the review text, the review title, the '\n",
            "                'star rating, an anonymized reviewer ID, an anonymized product '\n",
            "                'ID and the coarse-grained product category (e.g. ‘books’, '\n",
            "                '‘appliances’, etc.) The corpus is balanced across stars, so '\n",
            "                'each star rating constitutes 20% of the reviews in each '\n",
            "                'language.\\n'\n",
            "                '\\n'\n",
            "                'For each language, there are 200,000, 5,000 and 5,000 reviews '\n",
            "                'in the training, development and test sets respectively. The '\n",
            "                'maximum number of reviews per reviewer is 20 and the maximum '\n",
            "                'number of reviews per product is 20. All reviews are '\n",
            "                'truncated after 2,000 characters, and all reviews are at '\n",
            "                'least 20 characters long.\\n'\n",
            "                '\\n'\n",
            "                'Note that the language of a review does not necessarily match '\n",
            "                'the language of its marketplace (e.g. reviews from amazon.de '\n",
            "                'are primarily written in German, but could also be written in '\n",
            "                'English, etc.). For this reason, we applied a language '\n",
            "                'detection algorithm based on the work in Bojanowski et al. '\n",
            "                '(2017) to determine the language of the review text and we '\n",
            "                'removed reviews that were not written in the expected '\n",
            "                'language.\\n',\n",
            " 'download_checksums': {'https://amazon-reviews-ml.s3-us-west-2.amazonaws.com/json/dev/dataset_fr_dev.json': {'checksum': '6ec4446b78afcd3807af2cca642cbfd25aaf4cbf48ba60f3dbc2de8e7df91634',\n",
            "                                                                                                              'num_bytes': 2019337},\n",
            "                        'https://amazon-reviews-ml.s3-us-west-2.amazonaws.com/json/test/dataset_fr_test.json': {'checksum': '4728c7eea42b22d5b09a3c8d9846cfbbe8e5a21d05f250114010d466c23eb55e',\n",
            "                                                                                                                'num_bytes': 2044470},\n",
            "                        'https://amazon-reviews-ml.s3-us-west-2.amazonaws.com/json/train/dataset_fr_train.json': {'checksum': 'b6811b844f4889eedafa663c66d8f91454ed077ac0bf95242740bb60efcd0a53',\n",
            "                                                                                                                  'num_bytes': 81853486}},\n",
            " 'download_size': 85917293,\n",
            " 'features': {'language': Value(dtype='string', id=None),\n",
            "              'product_category': Value(dtype='string', id=None),\n",
            "              'product_id': Value(dtype='string', id=None),\n",
            "              'review_body': Value(dtype='string', id=None),\n",
            "              'review_id': Value(dtype='string', id=None),\n",
            "              'review_title': Value(dtype='string', id=None),\n",
            "              'reviewer_id': Value(dtype='string', id=None),\n",
            "              'stars': Value(dtype='int32', id=None)},\n",
            " 'homepage': 'https://registry.opendata.aws/amazon-reviews-ml/',\n",
            " 'license': 'By accessing the Multilingual Amazon Reviews Corpus (\"Reviews '\n",
            "            'Corpus\"), you agree that the Reviews Corpus is an Amazon Service '\n",
            "            'subject to the Amazon.com Conditions of Use '\n",
            "            '(https://www.amazon.com/gp/help/customer/display.html/ref=footer_cou?ie=UTF8&nodeId=508088) '\n",
            "            'and you agree to be bound by them, with the following additional '\n",
            "            'conditions:\\n'\n",
            "            '\\n'\n",
            "            'In addition to the license rights granted under the Conditions of '\n",
            "            'Use, Amazon or its content providers grant you a limited, '\n",
            "            'non-exclusive, non-transferable, non-sublicensable, revocable '\n",
            "            'license to access and use the Reviews Corpus for purposes of '\n",
            "            'academic research. You may not resell, republish, or make any '\n",
            "            'commercial use of the Reviews Corpus or its contents, including '\n",
            "            'use of the Reviews Corpus for commercial research, such as '\n",
            "            'research related to a funding or consultancy contract, '\n",
            "            'internship, or other relationship in which the results are '\n",
            "            'provided for a fee or delivered to a for-profit organization. You '\n",
            "            'may not (a) link or associate content in the Reviews Corpus with '\n",
            "            'any personal information (including Amazon customer accounts), or '\n",
            "            '(b) attempt to determine the identity of the author of any '\n",
            "            'content in the Reviews Corpus. If you violate any of the '\n",
            "            'foregoing conditions, your license to access and use the Reviews '\n",
            "            'Corpus will automatically terminate without prejudice to any of '\n",
            "            'the other rights or remedies Amazon may have.\\n',\n",
            " 'post_processed': None,\n",
            " 'post_processing_size': None,\n",
            " 'size_in_bytes': 143216131,\n",
            " 'splits': {'test': SplitInfo(name='test', num_bytes=1364510, num_examples=5000, dataset_name='amazon_reviews_multi'),\n",
            "            'train': SplitInfo(name='train', num_bytes=54593565, num_examples=200000, dataset_name='amazon_reviews_multi'),\n",
            "            'validation': SplitInfo(name='validation', num_bytes=1340763, num_examples=5000, dataset_name='amazon_reviews_multi')},\n",
            " 'supervised_keys': None,\n",
            " 'version': 1.0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE0E87zsvSUz"
      },
      "source": [
        "## Inspecting and using the dataset: elements, slices and columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKf4YFnevSU0"
      },
      "source": [
        "The returned `Dataset` object is a memory mapped dataset that behave similarly to a normal map-style dataset. It is backed by an Apache Arrow table which allows many interesting features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP1xPqSyvSU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3373bb-9b2a-4977-a20c-5ff20908d9e3"
      },
      "source": [
        "print(dataset_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
            "    num_rows: 200000\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiO3rC8yvSU2"
      },
      "source": [
        "You can query it's length and get items or slices like you would do normally with a python mapping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxLcdj2yvSU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86595e0a-aa3e-4263-8e50-a7d09a3cbf00"
      },
      "source": [
        "print(f\"👉Dataset len(dataset): {len(dataset_train)}\")\n",
        "print(\"\\n👉First item 'dataset[0]':\")\n",
        "pprint(dataset_train[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "👉Dataset len(dataset): 200000\n",
            "\n",
            "👉First item 'dataset[0]':\n",
            "{'language': 'fr',\n",
            " 'product_category': 'wireless',\n",
            " 'product_id': 'product_fr_0957872',\n",
            " 'review_body': \"La protection d'écran a l'air plutôt de bonne qualité et \"\n",
            "                \"adhère facilement à l'écran du téléphone, sauf que la \"\n",
            "                'protection est mal découpée pour le format. Tout le contour '\n",
            "                'est comme \"mal collé\" et cela donne l\\'impression d\\'une '\n",
            "                \"bulle d'air qui fait tout le contour du téléphone alors que \"\n",
            "                \"le centre est nickel. J'ai essayé les deux films en pensant \"\n",
            "                \"que l'un était peut-être défectueux ou que je l'avais \"\n",
            "                \"simplement mal posée, mais non. Au final, je l'ai retiré et \"\n",
            "                'je suis très déçu.',\n",
            " 'review_id': 'fr_0633486',\n",
            " 'review_title': \"Ne correspond pas parfaitement à l'écran du OnePlus 5T\",\n",
            " 'reviewer_id': 'reviewer_fr_0276908',\n",
            " 'stars': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RsmzdyO3b_X"
      },
      "source": [
        "## Create jsonl files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlTmKvmN3Y73"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAzCo2R5rwj5",
        "outputId": "e724dedc-1e68-4a2f-a979-6ee1826369b3"
      },
      "source": [
        "ner = dataset_train.features['ner_tags'].feature.names\n",
        "ner\n",
        "labels = {idx:lang for idx,lang in enumerate(ner)}\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'B-PER',\n",
              " 2: 'I-PER',\n",
              " 3: 'B-ORG',\n",
              " 4: 'I-ORG',\n",
              " 5: 'B-LOC',\n",
              " 6: 'I-LOC'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asTwsk1A4THQ"
      },
      "source": [
        "# def save_json_data(dataset, corpusname, lang, path):\n",
        "#   # splits = list(dataset.keys())\n",
        "#   back_data_dump = []\n",
        "\n",
        "#   # for split in splits:\n",
        "#   #   back_data = dataset[split]\n",
        "#   for idx in range(len(dataset)):\n",
        "#     data = dataset[idx]\n",
        "#     back_data_dump.append({'source':corpusname+ '-' +lang, 'ref_id':'train'+idx, 'data':{lang:data['text']} })\n",
        "    \n",
        "#   with open(path + corpusname+'-' +lang +'.jsonl', 'w') as output:\n",
        "#     for line in back_data_dump:\n",
        "#       json.dump(line, output, ensure_ascii=False, sort_keys=True)\n",
        "#       output.write('\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_json(dataset):\n",
        "  with open('/content/drive/MyDrive/Colab Notebooks/nlp-data/flue_pawsx_val.jsonl', 'w') as outfile:\n",
        "   # ner = dataset_train.features['ner_tags'].feature.names\n",
        "    #labels = {idx:lang for idx,lang in enumerate(ner)}\n",
        "    for idx in range(len(dataset)):\n",
        "      data = dataset[idx]\n",
        "     # ner_tags = [labels[i] for i in data['ner_tags']]\n",
        "      d = {\"source\":\"\", \"ref_id\":\"\", \"data\":{\"fr_1\":\"\", \"fr_2\":\"\"}}\n",
        "      d['source'] = \"flue_pawsx\"\n",
        "      d['ref_id'] =  \"val:\"+str(data['idx'])\n",
        "      d['data']['fr_1'] = clean_data(data['sentence1'])\n",
        "      d['data']['fr_2'] = clean_data(data['sentence2'])\n",
        "     # d['data']['en'] = clean_data(data['sentence_pair']['en'])\n",
        "      # d['data']['sentence_pair']['en'] = clean_data(data['sentence_pair']['en'])\n",
        "      # d['data']['sentence_pair']['fr'] = clean_data(data['sentence_pair']['fr'])\n",
        "      json.dump(d, outfile, ensure_ascii=False, sort_keys=True)\n",
        "      outfile.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oLyKoyLDAND"
      },
      "source": [
        "# path = '/content/drive/MyDrive/Colab Notebooks/nlp-data'\n",
        "dataset = dataset_val\n",
        "# corpusname = 'amazon_reviews_multi'\n",
        "# lang = 'fr'\n",
        "save_json(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g24wGE7QqoBx"
      },
      "source": [
        "amazon_review_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/nlp-data/amazon_reviews_multi.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re6HsczGq3fW"
      },
      "source": [
        "import re\n",
        "def clean_data(data):\n",
        "    x = str(data)\n",
        "    x = x.strip()\n",
        "   # x = re.sub(r'[^\\w\\s]','',x)\n",
        "   # x = re.sub(r'\\_','',x)\n",
        "    x = re.sub(r\"\\['\",'',x)\n",
        "    x = re.sub(r\"'\\]\",'',x)\n",
        "    x = re.sub(r'\\[\"','',x)\n",
        "    x = re.sub(r'\\\"]','',x)\n",
        "    x = re.sub(r'[-]+', '.', x)\n",
        "    x = re.sub(r'http\\S+','', x)\n",
        "    x = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', x)\n",
        "    x = re.sub('[\\u0621-\\u064A\\u0600-\\u06FF]', '', x)\n",
        "    x = re.sub(r\"[.']+\",'.',x)\n",
        "    x = re.sub(r\"[.,]+\",'.',x)\n",
        "    x = re.sub(r\"\\s{2,}\",'',x)\n",
        "    x = x.replace(r'. .', ' ')\n",
        "    x = x.replace(r'.', ' ')\n",
        "    x = x.replace(r']]', ' ')\n",
        "    x = x.replace(r' \"', ' ')\n",
        "    x = x.replace(r'\" ', ' ')\n",
        "    x = x.replace(r'  ', ' ')\n",
        "    x = x.replace(r'   ', ' ')\n",
        "    x = x.replace(r'( ', '(')\n",
        "    x = x.replace(r' )', ')')\n",
        "   # x = x.replace(str(x), \"[^\\w\\s]\", \"\")\n",
        "#     x = re.findall(r'\\w+', x)\n",
        "   # x = ' '.join(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_l38Fduq9gb"
      },
      "source": [
        "cl = clean_data(dataset_train['text'][10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "MYgkktwgWFvQ",
        "outputId": "079183b5-f374-40e9-a01e-9f292f1b1197"
      },
      "source": [
        "cl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'J ai lu ce livre en espagnol dans la langue natale de l ecrivan Je trouve l ouvrage excellent Non seulement par son histoire qui est passionante mais pour cet amour aux livres et à la literature qui se respire page après page Un roman bien écrit qui donne envie de lire qui donne envie de donner envie de lire A proposer tant en espagnol comme en français à tout le monde\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCDoomnXi1GI",
        "outputId": "d1429d1f-f075-470f-f9cc-ba58cb2bce34"
      },
      "source": [
        "def wikiann_converter(dataset):\n",
        "  labels = {idx:lang for idx,lang in enumerate(dataset.info.__dict__['features']['ner_tags'].feature.names) }\n",
        "  dat = {'ner_tags': [], 'tokens': []}\n",
        "  for idx in range(len(dataset)):\n",
        "    data = dataset[idx]\n",
        "    dat['tokens'].append(data['tokens'])\n",
        "    dat['ner_tags'].append([labels[i] for i in data['ner_tags']])\n",
        "  df = pd.DataFrame(dat)\n",
        "  df.to_csv('/content/drive/MyDrive/Colab Notebooks/data/kiny_ner_wikiann.csv', index=False)\n",
        "  return df\n",
        "df = wikiann_converter(dataset)\n",
        "df.info()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 300 entries, 0 to 299\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   ner_tags  300 non-null    object\n",
            " 1   tokens    300 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 4.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onyMlI8zepsv",
        "outputId": "4888e19e-375f-48a8-86c4-d4f841c2efd7"
      },
      "source": [
        "def wiki_2018_converter(dataset):\n",
        "  labels = {idx:lang for idx,lang in enumerate(dataset.info.__dict__['features']['label'].names) }\n",
        "  dat = {'language': [], 'sentences': []}\n",
        "  for idx in range(len(dataset)):\n",
        "    data = dataset[idx]\n",
        "    dat['sentences'].append(data['sentence'])\n",
        "    dat['language'].append(labels[data['label']])\n",
        "  df = pd.DataFrame(dat)\n",
        "  df.to_csv('/content/drive/MyDrive/Colab Notebooks/data/wiki_2018_multilingual.csv', index=False)\n",
        "  return df\n",
        "df = wiki_2018_converter(train_test_ds)\n",
        "df.info()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 117500 entries, 0 to 117499\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count   Dtype \n",
            "---  ------     --------------   ----- \n",
            " 0   language   117500 non-null  object\n",
            " 1   sentences  117500 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "4XYpSgrPi4mY",
        "outputId": "a3d38dd6-0273-4898-9bd4-26725f6010b5"
      },
      "source": [
        "# multilingual dataset\n",
        "\n",
        "def wiki_2018_summary(df):\n",
        "  lang = df.language\n",
        "  sent = df.sentences\n",
        "  dict_back = {'language': [], 'sentences': []}\n",
        "  for idx in range(len(sent)):\n",
        "    # l = lang[idx]\n",
        "    sentces = []\n",
        "    s = sent[idx].split('.')\n",
        "    l = [lang[idx]]*len(s)\n",
        "    for ss in s:\n",
        "      sentces.append(ss)\n",
        "    dict_back['language'].extend(l)\n",
        "    dict_back['sentences'].extend(sentces)\n",
        "  df_frame = pd.DataFrame(dict_back)\n",
        "  df_frame.to_csv('/content/drive/MyDrive/Colab Notebooks/data/amazon_review_multi_sent.csv', index=False)\n",
        "\n",
        "  char = []\n",
        "  for idxline in range(len(df_frame)):\n",
        "    char.extend([i for i in df_frame['sentences'][idxline]])\n",
        "  print('+------------------------+')\n",
        "  print()\n",
        "  print('Characters for all:',len(char), 'Sentences for all:', len(df_frame))\n",
        "  print()\n",
        "  print('+------------------------+')\n",
        "\n",
        "  return df_frame\n",
        "df_frame = wiki_2018_summary(dataset_fr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a54d27067885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdf_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdf_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwiki_2018_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-a54d27067885>\u001b[0m in \u001b[0;36mwiki_2018_summary\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwiki_2018_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mdict_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'language'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentences'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'language'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "S9L0aHRNlInI",
        "outputId": "720a2565-a304-4a33-a907-686b141a9dad"
      },
      "source": [
        "df_frame[df_frame['language']=='kin']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1669</th>\n",
              "      <td>kin</td>\n",
              "      <td>Mayoti (izina mu gifaransa : Collectivité dépa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1670</th>\n",
              "      <td>kin</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2236</th>\n",
              "      <td>kin</td>\n",
              "      <td>Igihe umwana w’umukobwa atangira kujya mu miha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2237</th>\n",
              "      <td>kin</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842</th>\n",
              "      <td>kin</td>\n",
              "      <td>Ibitabo bitanu bibanza bya Bibiliya byitwa, ib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519875</th>\n",
              "      <td>kin</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520138</th>\n",
              "      <td>kin</td>\n",
              "      <td>The multistakeholder approach were highlighted...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520139</th>\n",
              "      <td>kin</td>\n",
              "      <td>Sha Zukang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520140</th>\n",
              "      <td>kin</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520219</th>\n",
              "      <td>kin</td>\n",
              "      <td>Nimuyihe rugari yibonereho Ruhangwambone! Mbes...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1967 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       language                                          sentences\n",
              "1669        kin  Mayoti (izina mu gifaransa : Collectivité dépa...\n",
              "1670        kin                                                   \n",
              "2236        kin  Igihe umwana w’umukobwa atangira kujya mu miha...\n",
              "2237        kin                                                   \n",
              "3842        kin  Ibitabo bitanu bibanza bya Bibiliya byitwa, ib...\n",
              "...         ...                                                ...\n",
              "519875      kin                                                   \n",
              "520138      kin  The multistakeholder approach were highlighted...\n",
              "520139      kin                                         Sha Zukang\n",
              "520140      kin                                                   \n",
              "520219      kin  Nimuyihe rugari yibonereho Ruhangwambone! Mbes...\n",
              "\n",
              "[1967 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "vGqsjA30hLsM",
        "outputId": "20c9b4d6-2f4a-45a8-afe4-ce357ad13c75"
      },
      "source": [
        "df[df['language']=='kin']#['sentences']#[115923]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>kin</td>\n",
              "      <td>Mayoti (izina mu gifaransa : Collectivité dépa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>kin</td>\n",
              "      <td>Igihe umwana w’umukobwa atangira kujya mu miha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>kin</td>\n",
              "      <td>Ibitabo bitanu bibanza bya Bibiliya byitwa, ib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1603</th>\n",
              "      <td>kin</td>\n",
              "      <td>Itangazo Mpuzamahanga ryerekeye Uburenganzira ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2294</th>\n",
              "      <td>kin</td>\n",
              "      <td>Udimuritiya (izina mu cyudimuriti : Удмуртия c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115923</th>\n",
              "      <td>kin</td>\n",
              "      <td>Sena ikimara kujyaho mu 2003 yabanje gukorera ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115986</th>\n",
              "      <td>kin</td>\n",
              "      <td>Eritereya (izina mu gitigirinya : ኤርትራ cyangwa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117212</th>\n",
              "      <td>kin</td>\n",
              "      <td>Georg Wilhelm Friedrich Hegel (27 Kanama 1770 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117276</th>\n",
              "      <td>kin</td>\n",
              "      <td>The multistakeholder approach were highlighted...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117299</th>\n",
              "      <td>kin</td>\n",
              "      <td>Nimuyihe rugari yibonereho Ruhangwambone! Mbes...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       language                                          sentences\n",
              "369         kin  Mayoti (izina mu gifaransa : Collectivité dépa...\n",
              "500         kin  Igihe umwana w’umukobwa atangira kujya mu miha...\n",
              "835         kin  Ibitabo bitanu bibanza bya Bibiliya byitwa, ib...\n",
              "1603        kin  Itangazo Mpuzamahanga ryerekeye Uburenganzira ...\n",
              "2294        kin  Udimuritiya (izina mu cyudimuriti : Удмуртия c...\n",
              "...         ...                                                ...\n",
              "115923      kin  Sena ikimara kujyaho mu 2003 yabanje gukorera ...\n",
              "115986      kin  Eritereya (izina mu gitigirinya : ኤርትራ cyangwa...\n",
              "117212      kin  Georg Wilhelm Friedrich Hegel (27 Kanama 1770 ...\n",
              "117276      kin  The multistakeholder approach were highlighted...\n",
              "117299      kin  Nimuyihe rugari yibonereho Ruhangwambone! Mbes...\n",
              "\n",
              "[500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKE6FIgTG2RE"
      },
      "source": [
        "**SAVING DATA AS .CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b2pMgvKSyRt"
      },
      "source": [
        "dd= str(dataset)\n",
        "f = open(\"/content/drive/MyDrive/Colab Notebooks/nlp-data/euronews.txt\", \"a\")\n",
        "f.write(dd)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF-oVXUjGzRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6728be3-eb29-4170-ff4f-9bad4566fd7b"
      },
      "source": [
        "# MODIFY THIS ACCORDING TO THE FEATURES IN train_test_ds\n",
        "def get_data(data):\n",
        "  # dat = {'id': [], 'text': []}\n",
        "  # dat = {'text': []}\n",
        "  dat = {'stars': [], 'review_body': []}\n",
        "  for idx in range(len(data)):\n",
        "    d = data[idx]\n",
        "    dat['stars'].append(d['stars'])\n",
        "    dat['review_body'].append(d['review_body'])\n",
        "  df = pd.DataFrame(dat)\n",
        "  df.to_csv('/content/drive/MyDrive/Colab Notebooks/nlp-data/train.csv', index=False)\n",
        "  return df\n",
        "\n",
        "df1 = get_data(dataset_train)\n",
        "df1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200000 entries, 0 to 199999\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count   Dtype \n",
            "---  ------       --------------   ----- \n",
            " 0   stars        200000 non-null  int64 \n",
            " 1   review_body  200000 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 3.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvYYzD2Z88Rw"
      },
      "source": [
        "wikiann_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/nlp-data/wikiann_train_fr.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUuJUOnr9edU",
        "outputId": "657d8720-9437-41d0-86f6-09c4dcabde02"
      },
      "source": [
        "wikiann_train.head\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                    langs  ...                                             tokens\n",
              "0                                     ['fr', 'fr', 'fr']  ...                     ['Saxifrage', 'faux', 'Orpin']\n",
              "1                         ['fr', 'fr', 'fr', 'fr', 'fr']  ...       ['REDIRECTION', 'The', 'Lady', 'of', 'Rage']\n",
              "2                               ['fr', 'fr', 'fr', 'fr']  ...               ['Parti', 'libéral', 'du', 'Québec']\n",
              "3      ['fr', 'fr', 'fr', 'fr', 'fr', 'fr', 'fr', 'fr...  ...  ['Après', 'deux', 'nuls', '(', 'Guingamp', 'et...\n",
              "4       ['fr', 'fr', 'fr', 'fr', 'fr', 'fr', 'fr', 'fr']  ...  ['Ernst', 'Vettori', 'Richard', 'Schallert', '...\n",
              "...                                                  ...  ...                                                ...\n",
              "19995                                 ['fr', 'fr', 'fr']  ...                        ['Gaucher', 'de', 'Rethel']\n",
              "19996               ['fr', 'fr', 'fr', 'fr', 'fr', 'fr']  ...    ['Olympique', 'de', 'Marseille', '(', '3', ')']\n",
              "19997               ['fr', 'fr', 'fr', 'fr', 'fr', 'fr']  ...       [\"'\", \"''\", 'Le', 'Puy-en-Velay', \"''\", \"'\"]\n",
              "19998         ['fr', 'fr', 'fr', 'fr', 'fr', 'fr', 'fr']  ...  ['REDIRECTION', 'Aiguille', 'du', 'Plat', 'de'...\n",
              "19999                           ['fr', 'fr', 'fr', 'fr']  ...              ['Armée', 'polonaise', 'de', \"l'Est\"]\n",
              "\n",
              "[20000 rows x 3 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuGmPUJZ9hPm"
      },
      "source": [
        "kinya_en_ccaligned_multilingual = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/kinya_en_ccaligned_multilingual.csv')\n",
        "kinya_en_kd4_sent = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/kinya_en_kd4_sent.csv')\n",
        "\n",
        "yorba_en_ccaligned_multilingual_sent = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/yorba_en_ccaligned_multilingual_sent.csv')\n",
        "yorba_en_ccaligned_multilingual_doc = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/yorba_en_ccaligned_multilingual_doc.csv')\n",
        "yoruba_cc100_monolingual = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/yoruba_cc100_monolingual.csv')\n",
        "yoruba_menyo20k_mt = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/yoruba_menyo20k_mt.csv')\n",
        "yoruba_oscar_monolingual = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/yoruba_oscar_monolingual.csv')\n",
        "yoruba_text_c3 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/yoruba_text_c3.csv')\n",
        "yoruba_wikiann_monolingual = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/yoruba_wikiann_monolingual.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oQPtMGHMzOz"
      },
      "source": [
        "# lst = re.findall('\\S+@\\S+', kinya_en_ccaligned_multilingual.rw_RW[0])     \n",
        "# urls = re.findall('(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+', kinya_en_ccaligned_multilingual.rw_RW[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iyf33c5SJS7R"
      },
      "source": [
        "def clean(x):\n",
        "  x = x.strip()\n",
        "  x = re.sub(r'\\|', ' ', x)\n",
        "  lst = re.findall('\\S+@\\S+', x)     \n",
        "  urls = re.findall('(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+', x)\n",
        "  target = lst + urls\n",
        "  replacements = [t.replace('.', 'FFFF') for t in target]\n",
        "  for i in range(len(target)):\n",
        "    x = x.replace(target[i], replacements[i])\n",
        "  x = x.split('. ')\n",
        "  x = [o.replace('FFFF', '.') for o in x]\n",
        "  return x\n",
        "# kinya_en_ccaligned_multilingual['rw_RW_clean'] = kinya_en_ccaligned_multilingual.rw_RW.apply(clean)\n",
        "# kinya_en_ccaligned_multilingual['en_XX_clean'] = kinya_en_ccaligned_multilingual.en_XX.apply(clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAtee3fwo3mB"
      },
      "source": [
        "def generate_summary(dct):\n",
        "  rw = dct['allocine']\n",
        " # en = dct['en_XX']\n",
        "  kiny = []\n",
        "  #eng = []\n",
        "  for i in range(len(rw)):\n",
        "    kiny.extend([t for t in rw[i]])\n",
        "  # for i in range(len(en)):\n",
        "  #   eng.extend([e for e in en[i]])\n",
        "  \n",
        "  print('+------------------------+')\n",
        "  print()\n",
        "  print('Kinya characters:',len(kiny), 'Eng Characters:', len(eng))\n",
        "  # print()\n",
        "  # print('Kinya Sentences:',len(rw), 'Eng Sentences:', len(en))\n",
        "\n",
        "  print('+------------------------+')\n",
        "  return kiny"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtia8lNIPtBW"
      },
      "source": [
        "def create_sentences(df, summary= False):\n",
        "  path = '/content/drive/MyDrive/Colab Notebooks/nlp-data/'\n",
        "  dat = {'en_XX': []}\n",
        "  for i in range(len(df['en_XX'])):\n",
        "  #  bck_en = df['en_XX_clean'][i]\n",
        "    bck_rw = df['rw_RW_clean'][i]\n",
        "    # for en in bck_en:\n",
        "    #   dat['en_XX'].append(en)\n",
        "    for rw in bck_rw:\n",
        "      dat['rw_RW'].append(rw)\n",
        "\n",
        "  # with open(path + 'kinya_en_ccaligned_multilingual_sent.json', 'w') as fp:\n",
        "  #   json.dump(dat, fp)\n",
        "  # df = pd.DataFrame(dat)\n",
        "  # df.to_csv(path + 'kinya_en_ccaligned_multilingual_sent.csv', index=False)\n",
        "  if summary:\n",
        "    kiny = generate_summary(dat)\n",
        "\n",
        "  # return df, kiny, eng\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "yKZUYyQhSZRj",
        "outputId": "2d4a206b-2594-4565-c6b5-8b2cca77f7e0"
      },
      "source": [
        "# df, kiny, eng = create_sentences(kinya_en_ccaligned_multilingual)\n",
        "create_sentences(allocine, summary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'en_XX'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-bbbe861cbcb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# df, kiny, eng = create_sentences(kinya_en_ccaligned_multilingual)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcreate_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallocine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-81ecc5ce78ff>\u001b[0m in \u001b[0;36mcreate_sentences\u001b[0;34m(df, summary)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/nlp-data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'en_XX'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en_XX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;31m#  bck_en = df['en_XX_clean'][i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbck_rw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rw_RW_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'en_XX'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tbhbnp8JIHY",
        "outputId": "a91110ee-74ae-492c-814e-e9611b4c9234"
      },
      "source": [
        "def kd4_summary_kin(df):\n",
        "  rw = df.rw_RW\n",
        "  en = df.en_XX\n",
        "\n",
        "  kiny = []\n",
        "  eng = []\n",
        "\n",
        "  for i in range(len(rw)):\n",
        "    kiny.extend([t for t in rw[i]])\n",
        "  for i in range(len(en)):\n",
        "    eng.extend([e for e in en[i]])\n",
        "  print('+------------------------+')\n",
        "  print()\n",
        "  print('Kinya characters:',len(kiny), 'Eng Characters:', len(eng))\n",
        "  print()\n",
        "  print('Kinya Sentences:',len(rw), 'Eng Sentences:', len(en))\n",
        "\n",
        "  print('+------------------------+')\n",
        "kd4_summary_kin(kinya_en_kd4_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Kinya characters: 2637362 Eng Characters: 3688130\n",
            "\n",
            "Kinya Sentences: 39214 Eng Sentences: 39214\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-3umzvDY0gi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6222989-2e45-41fc-fc05-c7ebbdf95e9a"
      },
      "source": [
        "def ccaligned_multilingual_summary(df):\n",
        "  rw = df.yo_NG\n",
        "  en = df.en_XX\n",
        "\n",
        "  kiny = []\n",
        "  eng = []\n",
        "\n",
        "  for i in range(len(rw)):\n",
        "    if isinstance(rw[i],float):\n",
        "      kiny.extend([rw[i]])\n",
        "    else:\n",
        "      kiny.extend([t for t in rw[i]])\n",
        "  for i in range(len(en)):\n",
        "    if isinstance(en[i],float):\n",
        "      eng.extend([en[i]])\n",
        "    else:\n",
        "      eng.extend([e for e in en[i]])\n",
        "  print('+------------------------+')\n",
        "  print()\n",
        "  print('Yorba characters:',len(kiny), 'Eng Characters:', len(eng))\n",
        "  print()\n",
        "  print('Yorba Sentences:',len(rw), 'Eng Sentences:', len(en))\n",
        "\n",
        "  print('+------------------------+')\n",
        "ccaligned_multilingual_summary(yorba_en_ccaligned_multilingual_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Yorba characters: 16017824 Eng Characters: 16678283\n",
            "\n",
            "Yorba Sentences: 175192 Eng Sentences: 175192\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRBGFrufYPG4",
        "outputId": "5d346ca0-3b50-4c68-e636-9dd5ca1fb87d"
      },
      "source": [
        "def cleanyoruba_cc100(x):\n",
        "  x = str(x)\n",
        "  x = re.sub(r'\\n','',x)\n",
        "  x = x.strip()\n",
        "  return x\n",
        "def cc100_summary(df):\n",
        "  df['text'] = df.text.apply(cleanyoruba_cc100)\n",
        "  char = []\n",
        "  for t in df['text']:\n",
        "    char.extend([i for i in t])\n",
        "\n",
        "  print('+------------------------+')\n",
        "  print()\n",
        "  print('Yorba characters:',len(char), 'Yorba Sentences:', len(df['text']))\n",
        "  print('+------------------------+')\n",
        "  return df\n",
        "dfcc100 = cc100_summary(yoruba_cc100_monolingual)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Yorba characters: 4331484 Yorba Sentences: 76533\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDUwbrlpdXdl",
        "outputId": "a10f4020-02dd-43cc-df7a-ed97601c1764"
      },
      "source": [
        "dfoscar = cc100_summary(yoruba_oscar_monolingual)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Yorba characters: 18194 Yorba Sentences: 49\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9td-tN8d9v8",
        "outputId": "e157ccd5-5cc4-4f3a-ba15-c07b4947edb2"
      },
      "source": [
        "dfyoruba_text_c3 = cc100_summary(yoruba_text_c3)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Yorba characters: 53963606 Yorba Sentences: 562238\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXXg3HuyeWEe",
        "outputId": "35efb333-3097-495c-b6af-42803fba4265"
      },
      "source": [
        "dfyoruba_wikiann_monolingual = cc100_summary(yoruba_wikiann_monolingual)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Yorba characters: 122493 Yorba Sentences: 1719\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX6WhUEBYPEB",
        "outputId": "f6af7179-b8eb-4364-ea7f-23a028f1cd02"
      },
      "source": [
        "def menyo20k_summary(df):\n",
        "  yo = df.yo\n",
        "  en = df.en\n",
        "\n",
        "  yor = []\n",
        "  eng = []\n",
        "\n",
        "  for i in range(len(yo)):\n",
        "    yor.extend([t for t in yo[i]])\n",
        "  for i in range(len(en)):\n",
        "    eng.extend([e for e in en[i]])\n",
        "  print('+------------------------+')\n",
        "  print()\n",
        "  print('Yorba characters:',len(yor), 'Eng Characters:', len(eng))\n",
        "  print()\n",
        "  print('Yorba Sentences:',len(yo), 'Eng Sentences:', len(en))\n",
        "\n",
        "  print('+------------------------+')\n",
        "menyo20k_summary(yoruba_menyo20k_mt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Yorba characters: 1005556 Eng Characters: 1031517\n",
            "\n",
            "Yorba Sentences: 10070 Eng Sentences: 10070\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfwTlyWglrCc"
      },
      "source": [
        "# **SUMMARIES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej9Sa-u1lxiB"
      },
      "source": [
        "### **KINYARWANDA**\n",
        "\n",
        "\n",
        "\n",
        "1.   Monolingual\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc58EypxmNpW",
        "outputId": "986d5305-7129-42a4-dca6-f5f80d0e4b9a"
      },
      "source": [
        "kd4_summary_kin(kinya_en_kd4_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Kinya characters: 2637362 Eng Characters: 3688130\n",
            "\n",
            "Kinya Sentences: 39214 Eng Sentences: 39214\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slE4WJZ7mAnb"
      },
      "source": [
        "\n",
        "\n",
        "2.   Bilingual\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LypycmGmlSkM",
        "outputId": "85fd4c56-d809-4702-d950-f2369db53cb6"
      },
      "source": [
        "create_sentences(kinya_en_ccaligned_multilingual, summary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Kinya characters: 8976832 Eng Characters: 9563155\n",
            "\n",
            "Kinya Sentences: 33611 Eng Sentences: 37505\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn3cnGgPfloq"
      },
      "source": [
        "# **YORBA**\n",
        "\n",
        "\n",
        "\n",
        "1.   **Join Monolingual**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "FuNvkds5f1HS",
        "outputId": "2b062008-ee65-462e-c924-79cee013392f"
      },
      "source": [
        "yoruba_monolingual_sent = pd.DataFrame(dfcc100.text + dfoscar.text + dfyoruba_text_c3.text + dfyoruba_wikiann_monolingual.text)\n",
        "yoruba_monolingual_sent.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sístẹ́mù ajọfọ̀nàkò jẹ́ọ́gráfìCopyright © 2018...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ìforúkọsílẹ̀ àwọn olùdìbò àti gbígba káàdì ṣe ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fò kọjá sí nnkan tí ó wà nínú rẹ̀Àwọn Yorùbá n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ìrànlọ́wọ́ ÌwọléÀàrẹ fún ẹgbẹ́ àwọn ọmọbíbí ìp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ọjọ karun osu kẹrin ni wọn yoo gba abala akọkọ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  Sístẹ́mù ajọfọ̀nàkò jẹ́ọ́gráfìCopyright © 2018...\n",
              "1  Ìforúkọsílẹ̀ àwọn olùdìbò àti gbígba káàdì ṣe ...\n",
              "2  Fò kọjá sí nnkan tí ó wà nínú rẹ̀Àwọn Yorùbá n...\n",
              "3  Ìrànlọ́wọ́ ÌwọléÀàrẹ fún ẹgbẹ́ àwọn ọmọbíbí ìp...\n",
              "4  Ọjọ karun osu kẹrin ni wọn yoo gba abala akọkọ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IuamNfigZxE"
      },
      "source": [
        "yoruba_monolingual_sent.to_csv('/content/drive/MyDrive/Colab Notebooks/data/yoruba_monolingual_sent.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vBdgWULhO27",
        "outputId": "f9a73a0d-608a-425b-f74f-6c9c87505c22"
      },
      "source": [
        "yoruba_monolingual_summary = cc100_summary(yoruba_monolingual_sent)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Yorba characters: 1714698 Yorba Sentences: 562238\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoFKKlMMoU-O",
        "outputId": "bbc8f1c8-0ac3-42e0-816c-1737b1649688"
      },
      "source": [
        "yoruba_monolingual_summary.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 562238 entries, 0 to 562237\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    562238 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 8.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEn9sakuiSaq"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "2.   **Bilingual**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "uUxNS81KiRR4",
        "outputId": "fc11a73f-8285-4f5d-de0b-ef8aee26849f"
      },
      "source": [
        "eng = list(yorba_en_ccaligned_multilingual_sent.en_XX) + list(yoruba_menyo20k_mt.en)\n",
        "yorba = list(yorba_en_ccaligned_multilingual_sent.yo_NG) + list(yoruba_menyo20k_mt.yo)\n",
        "yoruba_bilingual_sent = pd.DataFrame({'en_XX': eng, 'yo_NG': yorba})\n",
        "yoruba_bilingual_sent.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_XX</th>\n",
              "      <th>yo_NG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the [Terrain] Section</td>\n",
              "      <td>Ko Laaye: lati fesi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"There is no God except Allah and Muhammad (PB...</td>\n",
              "      <td>Olohun ati gbigba Muhamadu, (Ki Alaafia ati Ib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Number of steps C 1234567891011121314151617181...</td>\n",
              "      <td>Number ti ni asiko C 1234567891011121314151617...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Phone: 086-13685849388</td>\n",
              "      <td>Foonu: 086-13685849388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When injected, it shall be diluted with steril...</td>\n",
              "      <td>Nigba ti itasi, o li ao ti fomi po pẹlu ni ifo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               en_XX                                              yo_NG\n",
              "0                           In the [Terrain] Section                               Ko Laaye: lati fesi.\n",
              "1  \"There is no God except Allah and Muhammad (PB...  Olohun ati gbigba Muhamadu, (Ki Alaafia ati Ib...\n",
              "2  Number of steps C 1234567891011121314151617181...  Number ti ni asiko C 1234567891011121314151617...\n",
              "3                             Phone: 086-13685849388                             Foonu: 086-13685849388\n",
              "4  When injected, it shall be diluted with steril...  Nigba ti itasi, o li ao ti fomi po pẹlu ni ifo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYX7IO9ziROj"
      },
      "source": [
        "yoruba_bilingual_sent.to_csv('/content/drive/MyDrive/Colab Notebooks/data/yoruba_bilingual_sent.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqMFy-q5kwAK",
        "outputId": "87067c7f-4632-41a5-faad-2cfb5f576d4e"
      },
      "source": [
        "ccaligned_multilingual_summary(yoruba_bilingual_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+\n",
            "\n",
            "Yorba characters: 17023380 Eng Characters: 17709800\n",
            "\n",
            "Yorba Sentences: 185262 Eng Sentences: 185262\n",
            "+------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGtdX-cPoOW8",
        "outputId": "bb5772b2-a9b4-42d1-a8ac-079618819fdb"
      },
      "source": [
        "yoruba_bilingual_sent.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 185262 entries, 0 to 185261\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   en_XX   185261 non-null  object\n",
            " 1   yo_NG   185261 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmJwGqzxHM_H"
      },
      "source": [
        "**END HERE!**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL6YKoI0HMox"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk1WQ_cczP5w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "3fe3d8c7-c97f-4c71-a15a-42825f86dfa4"
      },
      "source": [
        "# Or get slices with several examples:\n",
        "print(\"\\n👉Slice of the two items 'dataset[10:12]':\")\n",
        "pprint(dataset[10:12])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "👉Slice of the two items 'dataset[10:12]':\n",
            "OrderedDict([('answers',\n",
            "              [{'answer_start': [334, 334, 334],\n",
            "                'text': ['February 7, 2016', 'February 7', 'February 7, 2016']},\n",
            "               {'answer_start': [177, 177, 177],\n",
            "                'text': ['Denver Broncos',\n",
            "                         'Denver Broncos',\n",
            "                         'Denver Broncos']}]),\n",
            "             ('context',\n",
            "              ['Super Bowl 50 was an American football game to determine the '\n",
            "               'champion of the National Football League (NFL) for the 2015 '\n",
            "               'season. The American Football Conference (AFC) champion Denver '\n",
            "               'Broncos defeated the National Football Conference (NFC) '\n",
            "               'champion Carolina Panthers 24–10 to earn their third Super '\n",
            "               \"Bowl title. The game was played on February 7, 2016, at Levi's \"\n",
            "               'Stadium in the San Francisco Bay Area at Santa Clara, '\n",
            "               'California. As this was the 50th Super Bowl, the league '\n",
            "               'emphasized the \"golden anniversary\" with various gold-themed '\n",
            "               'initiatives, as well as temporarily suspending the tradition '\n",
            "               'of naming each Super Bowl game with Roman numerals (under '\n",
            "               'which the game would have been known as \"Super Bowl L\"), so '\n",
            "               'that the logo could prominently feature the Arabic numerals '\n",
            "               '50.',\n",
            "               'Super Bowl 50 was an American football game to determine the '\n",
            "               'champion of the National Football League (NFL) for the 2015 '\n",
            "               'season. The American Football Conference (AFC) champion Denver '\n",
            "               'Broncos defeated the National Football Conference (NFC) '\n",
            "               'champion Carolina Panthers 24–10 to earn their third Super '\n",
            "               \"Bowl title. The game was played on February 7, 2016, at Levi's \"\n",
            "               'Stadium in the San Francisco Bay Area at Santa Clara, '\n",
            "               'California. As this was the 50th Super Bowl, the league '\n",
            "               'emphasized the \"golden anniversary\" with various gold-themed '\n",
            "               'initiatives, as well as temporarily suspending the tradition '\n",
            "               'of naming each Super Bowl game with Roman numerals (under '\n",
            "               'which the game would have been known as \"Super Bowl L\"), so '\n",
            "               'that the logo could prominently feature the Arabic numerals '\n",
            "               '50.']),\n",
            "             ('id', ['56bea9923aeaaa14008c91bb', '56beace93aeaaa14008c91df']),\n",
            "             ('question',\n",
            "              ['What day was the Super Bowl played on?',\n",
            "               'Who won Super Bowl 50?']),\n",
            "             ('title', ['Super_Bowl_50', 'Super_Bowl_50'])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXj2Qr5KvSU5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9232ac73-1fe5-4bd2-de60-5716ef8f4201"
      },
      "source": [
        "# You can get a full column of the dataset by indexing with its name as a string:\n",
        "print(dataset['question'][:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Which NFL team represented the AFC at Super Bowl 50?', 'Which NFL team represented the NFC at Super Bowl 50?', 'Where did Super Bowl 50 take place?', 'Which NFL team won Super Bowl 50?', 'What color was used to emphasize the 50th anniversary of the Super Bowl?', 'What was the theme of Super Bowl 50?', 'What day was the game played on?', 'What is the AFC short for?', 'What was the theme of Super Bowl 50?', 'What does AFC stand for?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Au7rqPMvSU7"
      },
      "source": [
        "The `__getitem__` method will return different format depending on the type of query:\n",
        "\n",
        "- Items like `dataset[0]` are returned as dict of elements.\n",
        "- Slices like `dataset[10:20]` are returned as dict of lists of elements.\n",
        "- Columns like `dataset['question']` are returned as a list of elements.\n",
        "\n",
        "This may seems surprising at first but in our experiments it's actually a lot easier to use for data processing than returning the same format for each of these views on the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DB_y79cvSU8"
      },
      "source": [
        "In particular, you can easily iterate along columns in slices, and also naturally permute consecutive indexings with identical results as showed here by permuting column indexing with elements and slices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjGocqArvSU9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "22389a1d-2e3a-4d32-e125-8aed384df07d"
      },
      "source": [
        "print(dataset[0]['question'] == dataset['question'][0])\n",
        "print(dataset[10:20]['context'] == dataset['context'][10:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1-Kj1xQvSU_"
      },
      "source": [
        "### Dataset are internally typed and structured\n",
        "\n",
        "The dataset is backed by one (or several) Apache Arrow tables which are typed and allows for fast retrieval and access as well as arbitrary-size memory mapping.\n",
        "\n",
        "This means respectively that the format for the dataset is clearly defined and that you can load datasets of arbitrary size without worrying about RAM memory limitation (basically the dataset take no space in RAM, it's directly read from drive when needed with fast IO access)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAnp_RyPvSVA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "1ee0ace7-db77-4a9a-f6e4-c84cdb3f0bba"
      },
      "source": [
        "# You can inspect the dataset column names and types \n",
        "print(\"Column names:\")\n",
        "pprint(dataset.column_names)\n",
        "print(\"Features:\")\n",
        "pprint(dataset.features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column names:\n",
            "['answers', 'context', 'id', 'question', 'title']\n",
            "Features:\n",
            "{'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None),\n",
            " 'context': Value(dtype='string', id=None),\n",
            " 'id': Value(dtype='string', id=None),\n",
            " 'question': Value(dtype='string', id=None),\n",
            " 'title': Value(dtype='string', id=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au4v3mOQvSVC"
      },
      "source": [
        "### Additional misc properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efFhDWhlvSVC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f5bd2739-e52f-4e50-b3fe-afbd3f1f2427"
      },
      "source": [
        "# Datasets also have shapes informations\n",
        "print(\"The number of rows\", dataset.num_rows, \"also available as len(dataset)\", len(dataset))\n",
        "print(\"The number of columns\", dataset.num_columns)\n",
        "print(\"The shape (rows, columns)\", dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of rows 1057 also available as len(dataset) 1057\n",
            "The number of columns 5\n",
            "The shape (rows, columns) (1057, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ox7ppKDvSVN"
      },
      "source": [
        "## Modifying the dataset with `dataset.map`\n",
        "\n",
        "Now that we know how to inspect our dataset we also want to update it. For that there is a powerful method `.map()` which is inspired by `tf.data` map method and that you can use to apply a function to each examples, independently or in batch.\n",
        "\n",
        "`.map()` takes a callable accepting a dict as argument (same dict as the one returned by `dataset[i]`) and iterate over the dataset by calling the function on each example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz2-27HevSVN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "08236188125a4c2e931feb58ebe648c0",
            "58f37f73168648a08edc0ae615260c24",
            "1da82f72f3fc46358fe3e4268e42d137",
            "b051786ab97145cbb88627588bbec7d2",
            "97948303212c4a1982a6dda9dfd4cc90",
            "f252b203b8d349edb87b0a81209746b2",
            "37b19294c7464eb4bd886d966e148219",
            "1aa28417f911424eb9ac87413e4572ee"
          ]
        },
        "outputId": "183eafc7-fc4f-41ee-c342-7ff13ce09706"
      },
      "source": [
        "# Let's print the length of each `context` string in our subset of the dataset\n",
        "# (10% of the validation i.e. 1057 examples)\n",
        "\n",
        "dataset.map(lambda example: print(len(example['context']), end=','))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing the mapped function outputs\n",
            "Testing finished, running the mapping function on the dataset\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "775,"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08236188125a4c2e931feb58ebe648c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1057.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,179,179,179,179,179,179,179,179,179,179,179,168,168,168,168,168,168,168,168,168,168,168,168,168,168,168,168,168,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,704,704,704,704,704,704,704,704,704,704,704,704,704,704,353,353,353,353,353,353,353,353,353,353,353,353,353,353,353,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,306,306,306,306,306,306,306,306,306,306,306,306,372,372,372,372,372,372,372,372,372,372,372,372,372,372,372,372,372,496,496,496,496,496,496,496,496,496,496,496,496,496,496,496,260,260,260,260,260,260,260,260,260,874,874,874,874,874,874,874,874,874,874,874,874,874,874,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,176,176,176,176,176,176,176,176,176,176,176,176,176,176,176,176,782,782,782,782,782,782,782,782,782,782,782,782,782,782,782,782,536,536,536,536,536,536,536,536,536,666,666,666,666,666,666,666,666,666,666,666,666,666,666,666,666,666,495,495,495,495,495,495,495,495,495,495,495,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,441,441,441,441,441,441,441,441,441,441,441,357,357,357,357,357,357,357,357,357,296,296,296,296,296,296,296,296,296,296,644,644,644,644,644,644,644,644,644,644,644,644,644,644,644,644,644,804,804,804,804,804,804,804,804,804,804,804,397,397,397,397,397,397,397,397,397,397,397,397,397,397,360,360,360,360,360,360,360,973,973,973,973,973,973,973,973,973,973,973,973,973,973,263,263,263,263,263,263,263,263,263,263,263,568,568,568,568,568,568,568,568,568,568,568,264,264,264,264,264,264,264,264,264,264,264,264,264,264,264,892,892,892,892,892,892,892,892,892,892,892,206,206,206,206,206,489,489,489,489,489,489,489,489,489,489,489,489,489,181,181,181,181,181,181,181,181,181,181,181,181,531,531,531,531,531,531,531,531,531,531,531,531,664,664,664,664,664,664,664,664,664,664,664,664,664,664,672,672,672,672,672,672,672,672,672,672,672,672,672,672,858,858,858,858,858,858,858,858,858,858,858,858,634,634,634,634,634,634,634,634,634,634,634,634,634,634,891,891,891,891,891,891,891,891,891,891,891,891,891,488,488,488,488,488,488,488,488,488,488,488,488,942,942,942,942,942,942,942,942,942,942,942,942,942,942,942,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,522,522,522,522,522,1643,1643,1643,1643,1643,628,628,628,628,628,758,758,758,758,758,883,883,883,883,883,559,559,559,559,559,603,603,603,603,631,631,631,631,631,626,626,626,626,626,541,541,541,541,541,795,795,795,795,795,591,591,591,591,591,568,568,568,568,568,536,536,536,536,536,575,575,575,575,575,571,571,571,571,571,641,641,641,641,641,665,665,665,665,665,1088,1088,1088,1088,1088,1619,1619,1619,1619,1619,939,939,939,939,939,865,865,865,865,865,711,711,711,711,711,831,831,831,831,831,501,501,501,501,501,676,676,676,676,676,854,854,854,854,854,784,784,784,784,784,641,641,641,641,641,544,544,544,544,544,918,918,918,918,918,763,763,763,763,763,906,906,906,906,906,632,632,632,632,632,869,869,869,869,869,1044,1044,1044,1044,1044,760,760,760,760,760,715,715,715,715,715,838,838,838,838,838,881,881,881,881,881,940,940,940,940,940,618,618,618,618,618,1205,1205,1205,534,534,534,534,534,757,757,757,757,757,1239,1239,1239,1239,1239,609,609,609,609,609,798,798,798,798,798,613,613,613,613,613,613,613,613,613,613,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(features: {'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}, num_rows: 1057)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta3celHnvSVP"
      },
      "source": [
        "This is basically the same as doing\n",
        "\n",
        "```python\n",
        "for example in dataset:\n",
        "    function(example)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4Fjr0DJawuS"
      },
      "source": [
        "The above examples was a bit verbose. We can control the logging level of `🤗Datasets` with it's logging module:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAgptXFYaquI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f4c780cf-3a15-4043-9c51-2af530bcc0c2"
      },
      "source": [
        "from datasets import logging\n",
        "logging.set_verbosity_warning()\n",
        "\n",
        "dataset.map(lambda example: print(len(example['context']), end=','))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,179,179,179,179,179,179,179,179,179,179,179,168,168,168,168,168,168,168,168,168,168,168,168,168,168,168,168,168,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,704,704,704,704,704,704,704,704,704,704,704,704,704,704,353,353,353,353,353,353,353,353,353,353,353,353,353,353,353,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,306,306,306,306,306,306,306,306,306,306,306,306,372,372,372,372,372,372,372,372,372,372,372,372,372,372,372,372,372,496,496,496,496,496,496,496,496,496,496,496,496,496,496,496,260,260,260,260,260,260,260,260,260,874,874,874,874,874,874,874,874,874,874,874,874,874,874,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,176,176,176,176,176,176,176,176,176,176,176,176,176,176,176,176,782,782,782,782,782,782,782,782,782,782,782,782,782,782,782,782,536,536,536,536,536,536,536,536,536,666,666,666,666,666,666,666,666,666,666,666,666,666,666,666,666,666,495,495,495,495,495,495,495,495,495,495,495,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,441,441,441,441,441,441,441,441,441,441,441,357,357,357,357,357,357,357,357,357,296,296,296,296,296,296,296,296,296,296,644,644,644,644,644,644,644,644,644,644,644,644,644,644,644,644,644,804,804,804,804,804,804,804,804,804,804,804,397,397,397,397,397,397,397,397,397,397,397,397,397,397,360,360,360,360,360,360,360,973,973,973,973,973,973,973,973,973,973,973,973,973,973,263,263,263,263,263,263,263,263,263,263,263,568,568,568,568,568,568,568,568,568,568,568,264,264,264,264,264,264,264,264,264,264,264,264,264,264,264,892,892,892,892,892,892,892,892,892,892,892,206,206,206,206,206,489,489,489,489,489,489,489,489,489,489,489,489,489,181,181,181,181,181,181,181,181,181,181,181,181,531,531,531,531,531,531,531,531,531,531,531,531,664,664,664,664,664,664,664,664,664,664,664,664,664,664,672,672,672,672,672,672,672,672,672,672,672,672,672,672,858,858,858,858,858,858,858,858,858,858,858,858,634,634,634,634,634,634,634,634,634,634,634,634,634,634,891,891,891,891,891,891,891,891,891,891,891,891,891,488,488,488,488,488,488,488,488,488,488,488,488,942,942,942,942,942,942,942,942,942,942,942,942,942,942,942,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,522,522,522,522,522,1643,1643,1643,1643,1643,628,628,628,628,628,758,758,758,758,758,883,883,883,883,883,559,559,559,559,559,603,603,603,603,631,631,631,631,631,626,626,626,626,626,541,541,541,541,541,795,795,795,795,795,591,591,591,591,591,568,568,568,568,568,536,536,536,536,536,575,575,575,575,575,571,571,571,571,571,641,641,641,641,641,665,665,665,665,665,1088,1088,1088,1088,1088,1619,1619,1619,1619,1619,939,939,939,939,939,865,865,865,865,865,711,711,711,711,711,831,831,831,831,831,501,501,501,501,501,676,676,676,676,676,854,854,854,854,854,784,784,784,784,784,641,641,641,641,641,544,544,544,544,544,918,918,918,918,918,763,763,763,763,763,906,906,906,906,906,632,632,632,632,632,869,869,869,869,869,1044,1044,1044,1044,1044,760,760,760,760,760,715,715,715,715,715,838,838,838,838,838,881,881,881,881,881,940,940,940,940,940,618,618,618,618,618,1205,1205,1205,534,534,534,534,534,757,757,757,757,757,1239,1239,1239,1239,1239,609,609,609,609,609,798,798,798,798,798,613,613,613,613,613,613,613,613,613,613,"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(features: {'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}, num_rows: 1057)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfED6CEHa8J_"
      },
      "source": [
        "# Let's keep it verbose for our tutorial though\n",
        "from datasets import logging\n",
        "logging.set_verbosity_info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Ouw5gDvSVP"
      },
      "source": [
        "The above example had no effect on the dataset because the method we supplied to `.map()` didn't return a `dict` or a `abc.Mapping` that could be used to update the examples in the dataset.\n",
        "\n",
        "In such a case, `.map()` will return the same dataset (`self`).\n",
        "\n",
        "Now let's see how we can use a method that actually modify the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEnCi9DFvSVQ"
      },
      "source": [
        "### Modifying the dataset example by example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA37VgZhvSVQ"
      },
      "source": [
        "The main interest of `.map()` is to update and modify the content of the table and leverage smart caching and fast backend.\n",
        "\n",
        "To use `.map()` to update elements in the table you need to provide a function with the following signature: `function(example: dict) -> dict`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUr65K-4vSVQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "91d316b1-9fcc-44a7-b2f1-4af3b0c5c530"
      },
      "source": [
        "# Let's add a prefix 'My cute title: ' to each of our titles\n",
        "\n",
        "def add_prefix_to_title(example):\n",
        "    example['title'] = 'My cute title: ' + example['title']\n",
        "    return example\n",
        "\n",
        "prefixed_dataset = dataset.map(add_prefix_to_title)\n",
        "\n",
        "print(prefixed_dataset.unique('title'))  # `.unique()` is a super fast way to print the unique elemnts in a column (see the doc for all the methods)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing the mapped function outputs\n",
            "Testing finished, running the mapping function on the dataset\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-a5a4b682b7640362.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['My cute title: Super_Bowl_50', 'My cute title: Warsaw']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcZ_amDAvSVS"
      },
      "source": [
        "This call to `.map()` compute and return the updated table. It will also store the updated table in a cache file indexed by the current state and the mapped function.\n",
        "\n",
        "A subsequent call to `.map()` (even in another python session) will reuse the cached file instead of recomputing the operation.\n",
        "\n",
        "You can test this by running again the previous cell, you will see that the result are directly loaded from the cache and not re-computed again.\n",
        "\n",
        "The updated dataset returned by `.map()` is (again) directly memory mapped from drive and not allocated in RAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skbf8LUEvSVT"
      },
      "source": [
        "The function you provide to `.map()` should accept an input with the format of an item of the dataset: `function(dataset[0])` and return a python dict.\n",
        "\n",
        "The columns and type of the outputs can be different than the input dict. In this case the new keys will be added as additional columns in the dataset.\n",
        "\n",
        "Bascially each dataset example dict is updated with the dictionary returned by the function like this: `example.update(function(example))`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5De0CfTvSVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7ae32097-2117-4ebe-cd93-19eaad139579"
      },
      "source": [
        "# Since the input example dict is updated with our function output dict,\n",
        "# we can actually just return the updated 'title' field\n",
        "titled_dataset = dataset.map(lambda example: {'title': 'My cutest title: ' + example['title']})\n",
        "\n",
        "print(titled_dataset.unique('title'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing the mapped function outputs\n",
            "Testing finished, running the mapping function on the dataset\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-21992d783228fab5.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['My cutest title: Super_Bowl_50', 'My cutest title: Warsaw']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5vny56-vSVV"
      },
      "source": [
        "#### Removing columns\n",
        "You can also remove columns when running map with the `remove_columns=List[str]` argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sPWnsz-vSVW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3cac70f9-394f-4ef7-ffe3-e0d37d627d23"
      },
      "source": [
        "# This will remove the 'title' column while doing the update (after having send it the the mapped function so you can use it in your function!)\n",
        "less_columns_dataset = dataset.map(lambda example: {'new_title': 'Wouhahh: ' + example['title']}, remove_columns=['title'])\n",
        "\n",
        "print(less_columns_dataset.column_names)\n",
        "print(less_columns_dataset.unique('new_title'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing the mapped function outputs\n",
            "Testing finished, running the mapping function on the dataset\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-13610b40800136cb.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['answers', 'context', 'id', 'new_title', 'question']\n",
            "['Wouhahh: Super_Bowl_50', 'Wouhahh: Warsaw']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G459HzD-vSVY"
      },
      "source": [
        "#### Using examples indices\n",
        "With `with_indices=True`, dataset indices (from `0` to `len(dataset)`) will be supplied to the function which must thus have the following signature: `function(example: dict, indice: int) -> dict`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kFL37R2vSVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "d4f83cac-6e96-48c3-ba6b-6ffdd900712f"
      },
      "source": [
        "# This will add the index in the dataset to the 'question' field\n",
        "with_indices_dataset = dataset.map(lambda example, idx: {'question': f'{idx}: ' + example['question']},\n",
        "                                   with_indices=True)\n",
        "\n",
        "pprint(with_indices_dataset['question'][:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing the mapped function outputs\n",
            "Testing finished, running the mapping function on the dataset\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-c8fc174bebeb3456.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['0: Which NFL team represented the AFC at Super Bowl 50?',\n",
            " '1: Which NFL team represented the NFC at Super Bowl 50?',\n",
            " '2: Where did Super Bowl 50 take place?',\n",
            " '3: Which NFL team won Super Bowl 50?',\n",
            " '4: What color was used to emphasize the 50th anniversary of the Super Bowl?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xckhVEWFvSVb"
      },
      "source": [
        "### Modifying the dataset with batched updates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzmicbSnvSVb"
      },
      "source": [
        "`.map()` can also work with batch of examples (slices of the dataset).\n",
        "\n",
        "This is particularly interesting if you have a function that can handle batch of inputs like the tokenizers of HuggingFace `tokenizers`.\n",
        "\n",
        "To work on batched inputs set `batched=True` when calling `.map()` and supply a function with the following signature: `function(examples: Dict[List]) -> Dict[List]` or, if you use indices, `function(examples: Dict[List], indices: List[int]) -> Dict[List]`).\n",
        "\n",
        "Bascially, your function should accept an input with the format of a slice of the dataset: `function(dataset[:10])`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxHbgSTL0itj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "441ba953-8e69-4f74-d054-bb07804efecb"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7gpEg0yvSVc"
      },
      "source": [
        "# Let's import a fast tokenizer that can work on batched inputs\n",
        "# (the 'Fast' tokenizers in HuggingFace)\n",
        "from transformers import BertTokenizerFast, logging as transformers_logging\n",
        "\n",
        "transformers_logging.set_verbosity_warning()\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAmLTPC9vSVe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "0182e1b5-aa19-4739-b6ba-dc60e151998e"
      },
      "source": [
        "# Now let's batch tokenize our dataset 'context'\n",
        "encoded_dataset = dataset.map(lambda example: tokenizer(example['context']), batched=True)\n",
        "\n",
        "print(\"encoded_dataset[0]\")\n",
        "pprint(encoded_dataset[0], compact=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing the mapped function outputs\n",
            "Testing finished, running the mapping function on the dataset\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-56d381cc9390bb9f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "encoded_dataset[0]\n",
            "{'answers': {'answer_start': [177, 177, 177],\n",
            "             'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos']},\n",
            " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1],\n",
            " 'context': 'Super Bowl 50 was an American football game to determine the '\n",
            "            'champion of the National Football League (NFL) for the 2015 '\n",
            "            'season. The American Football Conference (AFC) champion Denver '\n",
            "            'Broncos defeated the National Football Conference (NFC) champion '\n",
            "            'Carolina Panthers 24–10 to earn their third Super Bowl title. The '\n",
            "            \"game was played on February 7, 2016, at Levi's Stadium in the San \"\n",
            "            'Francisco Bay Area at Santa Clara, California. As this was the '\n",
            "            '50th Super Bowl, the league emphasized the \"golden anniversary\" '\n",
            "            'with various gold-themed initiatives, as well as temporarily '\n",
            "            'suspending the tradition of naming each Super Bowl game with '\n",
            "            'Roman numerals (under which the game would have been known as '\n",
            "            '\"Super Bowl L\"), so that the logo could prominently feature the '\n",
            "            'Arabic numerals 50.',\n",
            " 'id': '56be4db0acb8001400a502ec',\n",
            " 'input_ids': [101, 3198, 5308, 1851, 1108, 1126, 1237, 1709, 1342, 1106, 4959,\n",
            "               1103, 3628, 1104, 1103, 1305, 2289, 1453, 113, 4279, 114, 1111,\n",
            "               1103, 1410, 1265, 119, 1109, 1237, 2289, 3047, 113, 10402, 114,\n",
            "               3628, 7068, 14722, 2378, 1103, 1305, 2289, 3047, 113, 24743, 114,\n",
            "               3628, 2938, 13598, 1572, 782, 1275, 1106, 7379, 1147, 1503, 3198,\n",
            "               5308, 1641, 119, 1109, 1342, 1108, 1307, 1113, 1428, 128, 117,\n",
            "               1446, 117, 1120, 12388, 112, 188, 3339, 1107, 1103, 1727, 2948,\n",
            "               2410, 3894, 1120, 3364, 10200, 117, 1756, 119, 1249, 1142, 1108,\n",
            "               1103, 13163, 3198, 5308, 117, 1103, 2074, 13463, 1103, 107, 5404,\n",
            "               5453, 107, 1114, 1672, 2284, 118, 12005, 11751, 117, 1112, 1218,\n",
            "               1112, 7818, 28117, 20080, 16264, 1103, 3904, 1104, 10505, 1296,\n",
            "               3198, 5308, 1342, 1114, 2264, 183, 15447, 16179, 113, 1223, 1134,\n",
            "               1103, 1342, 1156, 1138, 1151, 1227, 1112, 107, 3198, 5308, 149,\n",
            "               107, 114, 117, 1177, 1115, 1103, 7998, 1180, 15199, 2672, 1103,\n",
            "               4944, 183, 15447, 16179, 1851, 119, 102],\n",
            " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
            " 'title': 'Super_Bowl_50',\n",
            " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNaJdKskvSVf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7899e53-1bd9-4ea2-bf8d-60c127b3c6e2"
      },
      "source": [
        "# we have added additional columns\n",
        "pprint(dataset.column_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['answers', 'context', 'id', 'question', 'title']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3To8ztMvSVj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "ae210ea515f94c6ab34c1113e823b92d",
            "86c8850654d54b47a2771cbb1804f5a1",
            "435d36683bc04e06a971b76129a88ed1",
            "78ae08f5803f4cb29f7f63c2843e9db0",
            "703443b26d7d40aea83417de59b64a79",
            "cf940cf9ea3043b5abeb4c851ad23b77",
            "e319f183228b4f0dba1140d9cc1573ec",
            "a3d89c58eda640a6a8289ba0c5d549e2"
          ]
        },
        "outputId": "69eca4fb-d5ae-46c1-e586-29d75830f174"
      },
      "source": [
        "# Let show a more complex processing with the full preparation of the SQuAD dataset\n",
        "# for training a model from Transformers\n",
        "def convert_to_features(batch):\n",
        "    # Tokenize contexts and questions (as pairs of inputs)\n",
        "    input_pairs = list(zip())\n",
        "    encodings = tokenizer(batch['context'], batch['question'], truncation=True)\n",
        "\n",
        "    # Compute start and end tokens for labels\n",
        "    start_positions, end_positions = [], []\n",
        "    for i, answer in enumerate(batch['answers']):\n",
        "        first_char = answer['answer_start'][0]\n",
        "        last_char = first_char + len(answer['text'][0]) - 1\n",
        "        start_positions.append(encodings.char_to_token(i, first_char))\n",
        "        end_positions.append(encodings.char_to_token(i, last_char))\n",
        "\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "    return encodings\n",
        "\n",
        "encoded_dataset = dataset.map(convert_to_features, batched=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing the mapped function outputs\n",
            "Testing finished, running the mapping function on the dataset\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-0e160d356f9b057c.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae210ea515f94c6ab34c1113e823b92d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done writing 1057 examples in 5081257 bytes /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/tmpljoctb2h.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBnmSa46vSVl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "efca25d9-581e-46a2-f9e7-53aaf018ea7f"
      },
      "source": [
        "# Now our dataset comprise the labels for the start and end position\n",
        "# as well as the offsets for converting back tokens\n",
        "# in span of the original string for evaluation\n",
        "print(\"column_names\", encoded_dataset.column_names)\n",
        "print(\"start_positions\", encoded_dataset[:5]['start_positions'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "column_names ['answers', 'attention_mask', 'context', 'end_positions', 'id', 'input_ids', 'question', 'start_positions', 'title', 'token_type_ids']\n",
            "start_positions [34, 45, 80, 34, 98]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzOXxNzQvSVo"
      },
      "source": [
        "## formatting outputs for PyTorch, Tensorflow, Numpy, Pandas\n",
        "\n",
        "Now that we have tokenized our inputs, we probably want to use this dataset in a `torch.Dataloader` or a `tf.data.Dataset`.\n",
        "\n",
        "To be able to do this we need to tweak two things:\n",
        "\n",
        "- format the indexing (`__getitem__`) to return numpy/pytorch/tensorflow tensors, instead of python objects, and probably\n",
        "- format the indexing (`__getitem__`) to return only the subset of the columns that we need for our model inputs.\n",
        "\n",
        "  We don't want the columns `id` or `title` as inputs to train our model, but we could still want to keep them in the dataset, for instance for the evaluation of the model.\n",
        "    \n",
        "This is handled by the `.set_format(type: Union[None, str], columns: Union[None, str, List[str]])` where:\n",
        "\n",
        "- `type` define the return type for our dataset `__getitem__` method and is one of `[None, 'numpy', 'pandas', 'torch', 'tensorflow']` (`None` means return python objects), and\n",
        "- `columns` define the columns returned by `__getitem__` and takes the name of a column in the dataset or a list of columns to return (`None` means return all columns)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU2h_qQDvSVo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "15f14cbb-558b-4701-b6f8-0999d3570920"
      },
      "source": [
        "columns_to_return = ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
        "\n",
        "encoded_dataset.set_format(type='torch', columns=columns_to_return)\n",
        "\n",
        "# Our dataset indexing output is now ready for being used in a pytorch dataloader\n",
        "pprint(encoded_dataset[1], compact=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Set __getitem__(key) output type to torch for ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'] columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1]),\n",
            " 'end_positions': tensor(46),\n",
            " 'input_ids': tensor([  101,  3198,  5308,  1851,  1108,  1126,  1237,  1709,  1342,  1106,\n",
            "         4959,  1103,  3628,  1104,  1103,  1305,  2289,  1453,   113,  4279,\n",
            "          114,  1111,  1103,  1410,  1265,   119,  1109,  1237,  2289,  3047,\n",
            "          113, 10402,   114,  3628,  7068, 14722,  2378,  1103,  1305,  2289,\n",
            "         3047,   113, 24743,   114,  3628,  2938, 13598,  1572,   782,  1275,\n",
            "         1106,  7379,  1147,  1503,  3198,  5308,  1641,   119,  1109,  1342,\n",
            "         1108,  1307,  1113,  1428,   128,   117,  1446,   117,  1120, 12388,\n",
            "          112,   188,  3339,  1107,  1103,  1727,  2948,  2410,  3894,  1120,\n",
            "         3364, 10200,   117,  1756,   119,  1249,  1142,  1108,  1103, 13163,\n",
            "         3198,  5308,   117,  1103,  2074, 13463,  1103,   107,  5404,  5453,\n",
            "          107,  1114,  1672,  2284,   118, 12005, 11751,   117,  1112,  1218,\n",
            "         1112,  7818, 28117, 20080, 16264,  1103,  3904,  1104, 10505,  1296,\n",
            "         3198,  5308,  1342,  1114,  2264,   183, 15447, 16179,   113,  1223,\n",
            "         1134,  1103,  1342,  1156,  1138,  1151,  1227,  1112,   107,  3198,\n",
            "         5308,   149,   107,   114,   117,  1177,  1115,  1103,  7998,  1180,\n",
            "        15199,  2672,  1103,  4944,   183, 15447, 16179,  1851,   119,   102,\n",
            "         5979,  4279,  1264,  2533,  1103, 24743,  1120,  3198,  5308,  1851,\n",
            "          136,   102]),\n",
            " 'start_positions': tensor(45),\n",
            " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj1ukGIuvSVq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa7f4643-54c2-45ef-b33e-4881bc68a57d"
      },
      "source": [
        "# Note that the columns are not removed from the dataset, just not returned when calling __getitem__\n",
        "# Similarly the inner type of the dataset is not changed to torch.Tensor, the conversion and filtering is done on-the-fly when querying the dataset\n",
        "print(encoded_dataset.column_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['answers', 'attention_mask', 'context', 'end_positions', 'id', 'input_ids', 'question', 'start_positions', 'title', 'token_type_ids']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWmmUdatasetsvSVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "6e12d88f-8d39-414d-e340-fbecd65275b4"
      },
      "source": [
        "# We can remove the formatting with `.reset_format()`\n",
        "# or, identically, a call to `.set_format()` with no arguments\n",
        "encoded_dataset.reset_format()\n",
        "\n",
        "pprint(encoded_dataset[1], compact=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'answers': {'answer_start': [249, 249, 249],\n",
            "             'text': ['Carolina Panthers', 'Carolina Panthers',\n",
            "                      'Carolina Panthers']},\n",
            " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            " 'context': 'Super Bowl 50 was an American football game to determine the '\n",
            "            'champion of the National Football League (NFL) for the 2015 '\n",
            "            'season. The American Football Conference (AFC) champion Denver '\n",
            "            'Broncos defeated the National Football Conference (NFC) champion '\n",
            "            'Carolina Panthers 24–10 to earn their third Super Bowl title. The '\n",
            "            \"game was played on February 7, 2016, at Levi's Stadium in the San \"\n",
            "            'Francisco Bay Area at Santa Clara, California. As this was the '\n",
            "            '50th Super Bowl, the league emphasized the \"golden anniversary\" '\n",
            "            'with various gold-themed initiatives, as well as temporarily '\n",
            "            'suspending the tradition of naming each Super Bowl game with '\n",
            "            'Roman numerals (under which the game would have been known as '\n",
            "            '\"Super Bowl L\"), so that the logo could prominently feature the '\n",
            "            'Arabic numerals 50.',\n",
            " 'end_positions': 46,\n",
            " 'id': '56be4db0acb8001400a502ed',\n",
            " 'input_ids': [101, 3198, 5308, 1851, 1108, 1126, 1237, 1709, 1342, 1106, 4959,\n",
            "               1103, 3628, 1104, 1103, 1305, 2289, 1453, 113, 4279, 114, 1111,\n",
            "               1103, 1410, 1265, 119, 1109, 1237, 2289, 3047, 113, 10402, 114,\n",
            "               3628, 7068, 14722, 2378, 1103, 1305, 2289, 3047, 113, 24743, 114,\n",
            "               3628, 2938, 13598, 1572, 782, 1275, 1106, 7379, 1147, 1503, 3198,\n",
            "               5308, 1641, 119, 1109, 1342, 1108, 1307, 1113, 1428, 128, 117,\n",
            "               1446, 117, 1120, 12388, 112, 188, 3339, 1107, 1103, 1727, 2948,\n",
            "               2410, 3894, 1120, 3364, 10200, 117, 1756, 119, 1249, 1142, 1108,\n",
            "               1103, 13163, 3198, 5308, 117, 1103, 2074, 13463, 1103, 107, 5404,\n",
            "               5453, 107, 1114, 1672, 2284, 118, 12005, 11751, 117, 1112, 1218,\n",
            "               1112, 7818, 28117, 20080, 16264, 1103, 3904, 1104, 10505, 1296,\n",
            "               3198, 5308, 1342, 1114, 2264, 183, 15447, 16179, 113, 1223, 1134,\n",
            "               1103, 1342, 1156, 1138, 1151, 1227, 1112, 107, 3198, 5308, 149,\n",
            "               107, 114, 117, 1177, 1115, 1103, 7998, 1180, 15199, 2672, 1103,\n",
            "               4944, 183, 15447, 16179, 1851, 119, 102, 5979, 4279, 1264, 2533,\n",
            "               1103, 24743, 1120, 3198, 5308, 1851, 136, 102],\n",
            " 'question': 'Which NFL team represented the NFC at Super Bowl 50?',\n",
            " 'start_positions': 45,\n",
            " 'title': 'Super_Bowl_50',\n",
            " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyUOA07svSVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d3c2a6c9-a1ec-41c2-d438-66b68c5f7416"
      },
      "source": [
        "# The current format can be checked with `.format`,\n",
        "# which is a dict of the type and formatting\n",
        "pprint(encoded_dataset.format)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'columns': ['answers',\n",
            "             'attention_mask',\n",
            "             'context',\n",
            "             'end_positions',\n",
            "             'id',\n",
            "             'input_ids',\n",
            "             'question',\n",
            "             'start_positions',\n",
            "             'title',\n",
            "             'token_type_ids'],\n",
            " 'format_kwargs': {},\n",
            " 'output_all_columns': False,\n",
            " 'type': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyi2eMeSvSVv"
      },
      "source": [
        "# Wrapping this all up (PyTorch)\n",
        "\n",
        "Let's wrap this all up with the full code to load and prepare SQuAD for training a PyTorch model from HuggingFace `transformers` library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0j8BPLi6Qlv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "de8ed5f7-069b-4c99-8b62-8fa32d755192"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvExTIZWvSVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526,
          "referenced_widgets": [
            "71d89e94d82f4335b7ca7aaf4dba83ed",
            "f38913964ddb4e3eb6fc0cf087ab0f52",
            "4f03c8400d014b3bbb5e8dd4f63c5441",
            "23f45949b7f949859ecabab44b591553",
            "3ae2be9ec40f424a8b1f5a8139f6de04",
            "cb778df78c63405db22ede23c63f001a",
            "d46f8f656ea34972a4dd9b7554d62315",
            "a57ecf5ee6e043458af851dfd2e0b50d",
            "90004c044a5c4fbb884f881d8bc1d54b",
            "30e2b72ce2304332a202d92d606671f6",
            "810d81cd651d41f298ff4815fcf9f34a",
            "86fa8d2a2b204d8586cc8ab5ad2a1b7a",
            "6db8399610464d6e93ce82ad8bb7bfc4",
            "f684dcff9d4c4c10b6bb623c02465b14",
            "043e8d6ca6574bd4abcfdd7145162ceb",
            "ec53215a263e413eab01f74b66b9bff6"
          ]
        },
        "outputId": "cb34dcd4-9ddc-4195-9b9d-5442659f9798"
      },
      "source": [
        "import torch \n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Load our training dataset and tokenizer\n",
        "dataset = load_dataset('squad')\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
        "\n",
        "def get_correct_alignement(context, answer):\n",
        "    \"\"\" Some original examples in SQuAD have indices wrong by 1 or 2 character. We test and fix this here. \"\"\"\n",
        "    gold_text = answer['text'][0]\n",
        "    start_idx = answer['answer_start'][0]\n",
        "    end_idx = start_idx + len(gold_text)\n",
        "    if context[start_idx:end_idx] == gold_text:\n",
        "        return start_idx, end_idx       # When the gold label position is good\n",
        "    elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "        return start_idx-1, end_idx-1   # When the gold label is off by one character\n",
        "    elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "        return start_idx-2, end_idx-2   # When the gold label is off by two character\n",
        "    else:\n",
        "        raise ValueError()\n",
        "\n",
        "# Tokenize our training dataset\n",
        "def convert_to_features(example_batch):\n",
        "    # Tokenize contexts and questions (as pairs of inputs)\n",
        "    encodings = tokenizer(example_batch['context'], example_batch['question'], truncation=True)\n",
        "\n",
        "    # Compute start and end tokens for labels using Transformers's fast tokenizers alignement methods.\n",
        "    start_positions, end_positions = [], []\n",
        "    for i, (context, answer) in enumerate(zip(example_batch['context'], example_batch['answers'])):\n",
        "        start_idx, end_idx = get_correct_alignement(context, answer)\n",
        "        start_positions.append(encodings.char_to_token(i, start_idx))\n",
        "        end_positions.append(encodings.char_to_token(i, end_idx-1))\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "    return encodings\n",
        "\n",
        "encoded_dataset = dataset.map(convert_to_features, batched=True)\n",
        "\n",
        "# Format our dataset to outputs torch.Tensor to train a pytorch model\n",
        "columns = ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
        "encoded_dataset.set_format(type='torch', columns=columns)\n",
        "\n",
        "# Instantiate a PyTorch Dataloader around our dataset\n",
        "# Let's do dynamic batching (pad on the fly with our own collate_fn)\n",
        "def collate_fn(examples):\n",
        "    return tokenizer.pad(examples, return_tensors='pt')\n",
        "dataloader = torch.utils.data.DataLoader(encoded_dataset['train'], collate_fn=collate_fn, batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking /root/.cache/huggingface/datasets/7b651474ac7542b878f15522547e5a8db52b501a382dac1aafd9369fa8365228.85f43de978b9b25921cb78d7a2f2b350c04acdbaedb9ecb5f7101cd7c0950e68.py for additional imports.\n",
            "Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.0.0/datasets/squad/squad.py at /root/.cache/huggingface/modules/datasets_modules/datasets/squad\n",
            "Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.0.0/datasets/squad/squad.py at /root/.cache/huggingface/modules/datasets_modules/datasets/squad/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41\n",
            "Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.0.0/datasets/squad/squad.py to /root/.cache/huggingface/modules/datasets_modules/datasets/squad/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/squad.py\n",
            "Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.0.0/datasets/squad/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/squad/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/dataset_infos.json\n",
            "Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.0.0/datasets/squad/squad.py at /root/.cache/huggingface/modules/datasets_modules/datasets/squad/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/squad.json\n",
            "No config specified, defaulting to first: squad/plain_text\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/squad/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41\n",
            "Overwrite dataset info from restored data version.\n",
            "Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41\n",
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41)\n",
            "Constructing Dataset for split train, validation, from /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41\n",
            "100%|██████████| 2/2 [00:00<00:00, 112.85it/s]\n",
            "Testing the mapped function outputs\n",
            "Testing finished, running the mapping function on the dataset\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-e7b3266205088a40.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71d89e94d82f4335b7ca7aaf4dba83ed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done writing 87599 examples in 452536620 bytes /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/tmpboypobqr.\n",
            "Testing the mapped function outputs\n",
            "Testing finished, running the mapping function on the dataset\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-babdc7d3d6f2e7a0.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90004c044a5c4fbb884f881d8bc1d54b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done writing 10570 examples in 56664663 bytes /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/tmp1nbv0a6c.\n",
            "Set __getitem__(key) output type to torch for ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'] columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Set __getitem__(key) output type to torch for ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'] columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mHnwMx2vSVx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1c0942f3-68df-490b-d37a-8f63d2aae717"
      },
      "source": [
        "# Let's load a pretrained Bert model and a simple optimizer\n",
        "from transformers import BertForQuestionAnswering\n",
        "\n",
        "model = BertForQuestionAnswering.from_pretrained('distilbert-base-cased', return_dict=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing BertForQuestionAnswering: ['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biqDH9vpvSVz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "1a55ede4-bde6-4bd7-e945-7e4b54352f68"
      },
      "source": [
        "# Now let's train our model\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model.train().to(device)\n",
        "for i, batch in enumerate(dataloader):\n",
        "    batch.to(device)\n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    model.zero_grad()\n",
        "    print(f'Step {i} - loss: {loss:.3}')\n",
        "    if i > 5:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 - loss: 5.84\n",
            "Step 1 - loss: 5.88\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-185-7040b885f382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxZQ9Ms_vSV1"
      },
      "source": [
        "# Wrapping this all up (Tensorflow)\n",
        "\n",
        "Let's wrap this all up with the full code to load and prepare SQuAD for training a Tensorflow model (works only from the version 2.2.0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE8VSTYovSV2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f3c33f0-deb1-48d4-d778-c3d80172b22f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datasets\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Load our training dataset and tokenizer\n",
        "train_tf_dataset = datasets.load_dataset('squad', split=\"train\")\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased', return_dict=True)\n",
        "\n",
        "# Tokenize our training dataset\n",
        "# The only one diff here is that start_positions and end_positions\n",
        "# must be single dim list => [[23], [45] ...]\n",
        "# instead of => [23, 45 ...]\n",
        "def convert_to_tf_features(example_batch):\n",
        "    # Tokenize contexts and questions (as pairs of inputs)\n",
        "    encodings = tokenizer(example_batch['context'], example_batch['question'], truncation=True)\n",
        "\n",
        "    # Compute start and end tokens for labels using Transformers's fast tokenizers alignement methods.\n",
        "    start_positions, end_positions = [], []\n",
        "    for i, (context, answer) in enumerate(zip(example_batch['context'], example_batch['answers'])):\n",
        "        start_idx, end_idx = get_correct_alignement(context, answer)\n",
        "        start_positions.append([encodings.char_to_token(i, start_idx)])\n",
        "        end_positions.append([encodings.char_to_token(i, end_idx-1)])\n",
        "    \n",
        "    if start_positions and end_positions:\n",
        "      encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "    return encodings\n",
        "\n",
        "train_tf_dataset = train_tf_dataset.map(convert_to_tf_features, batched=True)\n",
        "\n",
        "def remove_none_values(example):\n",
        "  return not None in example[\"start_positions\"] or not None in example[\"end_positions\"]\n",
        "\n",
        "train_tf_dataset = train_tf_dataset.filter(remove_none_values, load_from_cache_file=False)\n",
        "columns = ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
        "train_tf_dataset.set_format(type='tensorflow', columns=columns)\n",
        "features = {x: train_tf_dataset[x].to_tensor(default_value=0, shape=[None, tokenizer.model_max_length]) for x in columns[:3]} \n",
        "labels = {\"output_1\": train_tf_dataset[\"start_positions\"].to_tensor(default_value=0, shape=[None, 1])}\n",
        "labels[\"output_2\"] = train_tf_dataset[\"end_positions\"].to_tensor(default_value=0, shape=[None, 1])\n",
        "tfdataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 88/88 [00:38<00:00,  2.30it/s]\n",
            "100%|██████████| 88/88 [00:38<00:00,  2.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0dfw8K8vSV4"
      },
      "source": [
        "# Let's load a pretrained TF2 Bert model and a simple optimizer\n",
        "from transformers import TFBertForQuestionAnswering\n",
        "\n",
        "model = TFBertForQuestionAnswering.from_pretrained(\"bert-base-cased\")\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits=True)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "model.compile(optimizer=opt,\n",
        "              loss={'output_1': loss_fn, 'output_2': loss_fn},\n",
        "              loss_weights={'output_1': 1., 'output_2': 1.},\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcYtiykmvSV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "4b755c1b-8e61-43ab-ffc6-d3e82ed4174d"
      },
      "source": [
        "# Now let's train our model\n",
        "\n",
        "model.fit(tfdataset, epochs=1, steps_per_epoch=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_question_answering_1/bert/pooler/dense/kernel:0', 'tf_bert_for_question_answering_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_question_answering_1/bert/pooler/dense/kernel:0', 'tf_bert_for_question_answering_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_question_answering_1/bert/pooler/dense/kernel:0', 'tf_bert_for_question_answering_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_question_answering_1/bert/pooler/dense/kernel:0', 'tf_bert_for_question_answering_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_question_answering_1/bert/pooler/dense/kernel:0', 'tf_bert_for_question_answering_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_question_answering_1/bert/pooler/dense/kernel:0', 'tf_bert_for_question_answering_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_question_answering_1/bert/pooler/dense/kernel:0', 'tf_bert_for_question_answering_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_question_answering_1/bert/pooler/dense/kernel:0', 'tf_bert_for_question_answering_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 97s 32s/step - loss: 12.2385 - output_1_loss: 6.0742 - output_2_loss: 6.1642 - output_1_accuracy: 0.0417 - output_2_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1a8b824908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eREDXWP6vSV8"
      },
      "source": [
        "# Metrics API\n",
        "\n",
        "`datasets` also provides easy access and sharing of metrics.\n",
        "\n",
        "This aspect of the library is still experimental and the API may still evolve more than the datasets API.\n",
        "\n",
        "Like datasets, metrics are added as small scripts wrapping common metrics in a common API.\n",
        "\n",
        "There are several reason you may want to use metrics with `datasets` and in particular:\n",
        "\n",
        "- metrics for specific datasets like GLUE or SQuAD are provided out-of-the-box in a simple, convenient and consistant way integrated with the dataset,\n",
        "- metrics in `datasets` leverage the powerful backend to provide smart features out-of-the-box like support for distributed evaluation in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUoGMMVKvSV8"
      },
      "source": [
        "## Using metrics\n",
        "\n",
        "Using metrics is pretty simple, they have two main methods: `.compute(predictions, references)` to directly compute the metric and `.add(prediction, reference)` or `.add_batch(predictions, references)` to only store some results if you want to do the evaluation in one go at the end.\n",
        "\n",
        "Here is a quick gist of a standard use of metrics (the simplest usage):\n",
        "```python\n",
        "from datasets import load_metric\n",
        "sacrebleu_metric = load_metric('sacrebleu')\n",
        "\n",
        "# If you only have a single iteration, you can easily compute the score like this\n",
        "predictions = model(inputs)\n",
        "score = sacrebleu_metric.compute(predictions, references)\n",
        "\n",
        "# If you have a loop, you can \"add\" your predictions and references at each iteration instead of having to save them yourself (the metric object store them efficiently for you)\n",
        "for batch in dataloader:\n",
        "    model_input, targets = batch\n",
        "    predictions = model(model_inputs)\n",
        "    sacrebleu_metric.add_batch(predictions, targets)\n",
        "score = sacrebleu_metric.compute()  # Compute the score from all the stored predictions/references\n",
        "```\n",
        "\n",
        "Here is a quick gist of a use in a distributed torch setup (should work for any python multi-process setup actually). It's pretty much identical to the second example above:\n",
        "```python\n",
        "from datasets import load_metric\n",
        "# You need to give the total number of parallel python processes (num_process) and the id of each process (process_id)\n",
        "bleu_metric = datasets.load_metric('sacrebleu', process_id=torch.distributed.get_rank(),b num_process=torch.distributed.get_world_size())\n",
        "\n",
        "for batch in dataloader:\n",
        "    model_input, targets = batch\n",
        "    predictions = model(model_inputs)\n",
        "    sacrebleu_metric.add_batch(predictions, targets)\n",
        "score = sacrebleu_metric.compute()  # Compute the score on the first node by default (can be set to compute on each node as well)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySL-vDadvSV8"
      },
      "source": [
        "Example with a NER metric: `seqeval`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4uZym7MvSV9"
      },
      "source": [
        "!pip install seqeval\n",
        "ner_metric = load_metric('seqeval')\n",
        "references = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
        "predictions =  [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
        "ner_metric.compute(predictions=predictions, references=references)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctY6AIAilLdH"
      },
      "source": [
        "# Adding a new dataset or a new metric\n",
        "\n",
        "They are two ways to add new datasets and metrics in `datasets`:\n",
        "\n",
        "- datasets can be added with a Pull-Request adding a script in the `datasets` folder of the [`datasets` repository](https://github.com/huggingface/datasets)\n",
        "\n",
        "=> once the PR is merged, the dataset can be instantiate by it's folder name e.g. `datasets.load_dataset('squad')`. If you want HuggingFace to host the data as well you will need to ask the HuggingFace team to upload the data.\n",
        "\n",
        "- datasets can also be added with a direct upload using `datasets` CLI as a user or organization (like for models in `transformers`). In this case the dataset will be accessible under the gien user/organization name, e.g. `datasets.load_dataset('thomwolf/squad')`. In this case you can upload the data yourself at the same time and in the same folder.\n",
        "\n",
        "See more information in [the dataset sharing section of the documentation](https://huggingface.co/docs/datasets/share_dataset.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ7KAWe51dia",
        "outputId": "11b2896e-a15f-4a5b-e067-bd2acc8ef560"
      },
      "source": [
        "cd drive/MyDrive/Colab\\ Notebooks/nlp-data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/nlp-data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXolS9WMKLBn",
        "outputId": "f29e7512-3e9b-4389-cffe-faf654462804"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "allocine.csv\t\t       bible_para.jsonl        flue_pawsx_val.jsonl\n",
            "allocine_test.jsonl\t       euronews.txt\t       refresd.csv\n",
            "allocine_train.jsonl\t       flue_cls_test.csv       refresd.jsonl\n",
            "allocine_val.jsonl\t       flue_cls_test.jsonl     wikiann_fr_test.jsonl\n",
            "amazon_reviews_fr_test.jsonl   flue_cls_train.csv      wikiann_fr_train.jsonl\n",
            "amazon_reviews_fr_train.jsonl  flue_cls_train.jsonl    wikiann_fr_val.jsonl\n",
            "amazon_reviews_fr_val.jsonl    flue_pawsx.csv\t       wikiann_test_fr.csv\n",
            "amazon_reviews_multi.csv       flue_pawsx_test.jsonl   wikiann_train_fr.csv\n",
            "amazon_reviews_multi_fr.csv    flue_pawsx_train.jsonl  wikiann_val_fr.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypLjbtGrljk8"
      },
      "source": [
        "import csv\n",
        "import json\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKPiKWsTKYRX"
      },
      "source": [
        "df = pd.read_json ('allocine_test.jsonl', lines=True)\n",
        "export_csv = df.to_csv ('allocine_test.csv', index = None, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "dyhiryP41PNQ",
        "outputId": "6ec5518f-ce8d-4043-8971-cd1ecfd9a1fa"
      },
      "source": [
        "# Function to convert a CSV to JSON\n",
        "# Takes the file paths as arguments\n",
        "def make_json(csvFilePath, corpusname, jsonFilePath):\n",
        "     \n",
        "    # create a dictionary\n",
        "    data = {}\n",
        "     \n",
        "    # Open a csv reader called DictReader\n",
        "    with open(csvFilePath, encoding='utf-8') as csvf:\n",
        "        csvReader = csv.DictReader(csvf)\n",
        "         \n",
        "        # Convert each row into a dictionary\n",
        "        # and add it to data\n",
        "        for rows in csvReader:\n",
        "             \n",
        "            # Assuming a column named 'No' to\n",
        "            # be the primary key\n",
        "            key = rows['review_id']\n",
        "            data[key] =  rows\n",
        "            #{'source': corpusname} + data\n",
        "            data.update({'source': corpusname})\n",
        " \n",
        "    # Open a json writer, and use the json.dumps()\n",
        "    # function to dump data\n",
        "    with open(jsonFilePath , 'w', encoding='utf-8') as jsonf:\n",
        "        jsonf.write(json.dumps(data,ensure_ascii = False, sort_keys=True , indent=4))\n",
        "       # jsonf.write(json.dump())\n",
        "         \n",
        "# Driver Code\n",
        " \n",
        "# Decide the two file paths according to your\n",
        "# computer system\n",
        "csvFilePath = r'/content/drive/MyDrive/Colab Notebooks/nlp-data/amazon_reviews_multi_fr.csv'\n",
        "jsonFilePath = r'/content/drive/MyDrive/Colab Notebooks/nlp-data/amazon_reviews_multi_fr.jsonl'\n",
        "corpusname = 'amazon_reviews_fr'\n",
        "# Call the make_json function\n",
        "make_json(csvFilePath, corpusname, jsonFilePath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6424792afdc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mcorpusname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'amazon_reviews_fr'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Call the make_json function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mmake_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpusname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjsonFilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-6424792afdc8>\u001b[0m in \u001b[0;36mmake_json\u001b[0;34m(csvFilePath, corpusname, jsonFilePath)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Open a csv reader called DictReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mcsvReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/nlp-data/amazon_reviews_multi_fr.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpk-AUdC2frs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}